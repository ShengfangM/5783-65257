{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDLECHCQebBb"
      },
      "outputs": [],
      "source": [
        "#  these code refered from keras document https://keras.io/examples/vision/mnist_convnet/\n",
        "\n",
        "# import library\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "import tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wL_g1sruIoj"
      },
      "source": [
        "#Question 1 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYxsWL2jw3Lj"
      },
      "source": [
        "First I tested the effect of batch size. I use epoch = 5, default Adam optimizer. I tested the accuracy when batchsize is 1, 5, 10, 32, 64, 128,256 respectively. When batchsize = 1, the accuracy is 0.79. When batchsize = 5, the accuracy is 0.83. When batchsize = 5, the accuracy is 0.98. The accuracy is 0.99 when batchsize is 32,64,128. \n",
        "\n",
        "Then I tested the effect of learning rate. I used epoch = 5, batch size is 128, default Adam optimizer.  I tested the accuracy when learning rate is 0.01, 0.005, 0.001, 0.0005, 0.0001 respectively. When learning rate is 0.01,  test accuracy is 0.10. When learning rate is 0.005,  test accuracy is 0.11. When learning rate is 0.001,  test accuracy is  0.984. When learning rate is 0.0005 and 0.0001,  test accuracy is 0.99. \n",
        "\n",
        "Then I tested the effect of the optimizer. I used epoch = 5, batch size is 128,the default Adam, SGD, and RMSprop optimizer. All three optimizers have the test accuracy of 0.99. \n",
        "\n",
        "The final accuracy of the regular CNN is 0.99, inverted CNN, and hour-glass shaped CNN are all 0.987. Regular CNN is slightly better than the other two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZKBsgAjQ2E",
        "outputId": "2562d913-e39b-41c3-d261-71eac1b500be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "# number of classes\n",
        "n_class = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(image_train, class_train),(image_test, class_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "image_train = image_train.astype(\"float32\") / 255\n",
        "image_test = image_test.astype(\"float32\") / 255\n",
        "\n",
        "#add an additional dimension to represent the single-channel\n",
        "x_train = image_train.reshape(-1, 28, 28, 1) \n",
        "x_test = image_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(class_train, n_class)\n",
        "y_test = keras.utils.to_categorical(class_test, n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs69yf4nk2ij"
      },
      "source": [
        "1.1. A regular CNN where the number of filters in each layer increases as the depth of the network grows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOHBJ4ZQrzLf",
        "outputId": "1b007e06-41c1-436f-a694-759cefc1f7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 28, 28, 6)            60        \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 28, 28, 10)           550       \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 28, 28, 16)           1456      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (1, 14, 14, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (1, 14, 14, 24)           3480      \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 14, 14, 32)           6944      \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 14, 14, 48)           13872     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (1, 7, 7, 48)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (1, 7, 7, 64)             27712     \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 7, 7, 96)             55392     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (1, 3, 3, 96)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 3, 3, 128)            110720    \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (1, 3, 3, 256)            295168    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (1, 1, 1, 256)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 256)                  0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 256)                  65792     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 256)                  0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   2570      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 583,716\n",
            "Trainable params: 583,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(10, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(24, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(48, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(96, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(128, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(256, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn.add(keras.layers.Flatten())\n",
        "regular_cnn.add(keras.layers.Dense(256))\n",
        "regular_cnn.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn.add(keras.layers.Dense(n_class))\n",
        "regular_cnn.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w6ySAOLl9W5",
        "outputId": "0c6cb364-1d2b-4a2e-839b-520c71b3e232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5400/5400 [==============================] - 42s 6ms/step - loss: 0.1995 - accuracy: 0.9380 - val_loss: 0.0689 - val_accuracy: 0.9805\n",
            "Epoch 2/5\n",
            "5400/5400 [==============================] - 33s 6ms/step - loss: 0.0761 - accuracy: 0.9789 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
            "Epoch 3/5\n",
            "5400/5400 [==============================] - 32s 6ms/step - loss: 0.0629 - accuracy: 0.9827 - val_loss: 0.0392 - val_accuracy: 0.9897\n",
            "Epoch 4/5\n",
            "5400/5400 [==============================] - 32s 6ms/step - loss: 0.0560 - accuracy: 0.9854 - val_loss: 0.0437 - val_accuracy: 0.9895\n",
            "Epoch 5/5\n",
            "5400/5400 [==============================] - 33s 6ms/step - loss: 0.0529 - accuracy: 0.9860 - val_loss: 0.0368 - val_accuracy: 0.9905\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0347 - accuracy: 0.9903\n",
            "Test loss: 0.03468652814626694\n",
            "Test accuracy: 0.9902999997138977\n"
          ]
        }
      ],
      "source": [
        "# test the effect of batch size to test accuracy\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # test the effect of learning rate to test accuracy\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "opt1 = keras.optimizers.Adam(learning_rate=0.005)\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer=opt1, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnZvMVefcZCi",
        "outputId": "a703a5e9-2918-4262-dd0a-649cf06c71b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 5s 10ms/step - loss: 0.5600 - accuracy: 0.8022 - val_loss: 0.0985 - val_accuracy: 0.9707\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.1055 - accuracy: 0.9683 - val_loss: 0.0647 - val_accuracy: 0.9803\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.0543 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0686 - accuracy: 0.9802 - val_loss: 0.0556 - val_accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 0.0516 - val_accuracy: 0.9843\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9863\n",
            "Test loss: 0.04517043009400368\n",
            "Test accuracy: 0.986299991607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e24Eb8CO9y5",
        "outputId": "abffad48-3f48-4bcf-803a-fdc7c99ae334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 6s 11ms/step - loss: 0.2797 - accuracy: 0.9092 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0579 - accuracy: 0.9814 - val_loss: 0.0393 - val_accuracy: 0.9878\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 5s 13ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 4s 11ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0334 - val_accuracy: 0.9907\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0271 - val_accuracy: 0.9922\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9919\n",
            "Test loss: 0.026087500154972076\n",
            "Test accuracy: 0.9919000267982483\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # test the effect of optimizer to test accuracy\n",
        "\n",
        "# opt1 = keras.optimizers.Adam(learning_rate=0.001)\n",
        "# opt2 = keras.optimizers.SGD(learning_rate=0.001)\n",
        "# opt3 = keras.optimizers.RMSprop( learning_rate=0.001,   rho=0.9,   momentum=0.0)\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sPSrgreupmi"
      },
      "source": [
        "1.2. An inverted CNN where the number of filters in each layer decreases as the depth of the network grows "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IG76hoQupGf",
        "outputId": "84bb317c-541d-4f31-f1bd-421131bd1584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (1, 28, 28, 256)          2560      \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (1, 28, 28, 128)          295040    \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (1, 28, 28, 96)           110688    \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (1, 14, 14, 96)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (1, 14, 14, 64)           55360     \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (1, 14, 14, 48)           27696     \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (1, 14, 14, 32)           13856     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (1, 7, 7, 32)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (1, 7, 7, 24)             6936      \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (1, 7, 7, 16)             3472      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (1, 3, 3, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (1, 3, 3, 10)             1450      \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (1, 3, 3, 6)              546       \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (1, 1, 1, 6)             0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 6)                    0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (1, 1024)                 7168      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (1, 10)                   10250     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,022\n",
            "Trainable params: 535,022\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn2 = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn2.add(keras.layers.Conv2D(256, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(96, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn2.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(48, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn2.add(keras.layers.Conv2D(24, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "regular_cnn2.add(keras.layers.Conv2D(10, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(768, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(1024, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn2.add(keras.layers.Flatten())\n",
        "regular_cnn2.add(keras.layers.Dense(1024))\n",
        "regular_cnn2.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn2.add(keras.layers.Dense(n_class))\n",
        "regular_cnn2.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn2.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn2.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn2.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMUstp0DTew",
        "outputId": "689f17de-32ec-4334-d3a9-4de9fa15a264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 24s 52ms/step - loss: 0.3497 - accuracy: 0.8839 - val_loss: 0.0816 - val_accuracy: 0.9748\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 21s 49ms/step - loss: 0.0858 - accuracy: 0.9747 - val_loss: 0.0744 - val_accuracy: 0.9792\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.0414 - val_accuracy: 0.9875\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 0.0326 - val_accuracy: 0.9913\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0389 - accuracy: 0.9879\n",
            "Test loss: 0.03893260285258293\n",
            "Test accuracy: 0.9879000186920166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3. An hour-glass shaped CNN where the number of filters will increase till the Lth layer and reduce afterwards"
      ],
      "metadata": {
        "id": "ZEkMWh9_415M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn3 = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn3.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn3.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(96, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(128, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn3.add(keras.layers.Conv2D(96, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "regular_cnn3.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(768, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(1024, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn3.add(keras.layers.Flatten())\n",
        "regular_cnn3.add(keras.layers.Dense(1024))\n",
        "regular_cnn3.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn3.add(keras.layers.Dense(n_class))\n",
        "regular_cnn3.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn3.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chBNuPSX40cu",
        "outputId": "8c8ed846-56cd-448c-cd2a-5e746736c8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (1, 28, 28, 6)            60        \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (1, 28, 28, 16)           880       \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (1, 28, 28, 32)           4640      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (1, 14, 14, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (1, 14, 14, 64)           18496     \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (1, 14, 14, 96)           55392     \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (1, 14, 14, 128)          110720    \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (1, 7, 7, 128)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (1, 7, 7, 96)             110688    \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (1, 7, 7, 64)             55360     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (1, 3, 3, 64)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (1, 3, 3, 32)             18464     \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (1, 3, 3, 16)             4624      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (1, 1, 1, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 16)                   0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (1, 1024)                 17408     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (1, 10)                   10250     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 406,982\n",
            "Trainable params: 406,982\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn3.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn3.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "outputId": "7b240a22-3dc5-4453-c843-25c8a288d426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBDvoBOQEMRY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 9s 17ms/step - loss: 0.4029 - accuracy: 0.8636 - val_loss: 0.1007 - val_accuracy: 0.9683\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.1011 - accuracy: 0.9685 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0642 - accuracy: 0.9801 - val_loss: 0.0505 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.0478 - val_accuracy: 0.9858\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9875\n",
            "Test loss: 0.04437745735049248\n",
            "Test accuracy: 0.987500011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngL3xaFvfvev"
      },
      "source": [
        "# Question 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78E2KxfCe2Hf"
      },
      "source": [
        "1. What is the effect of learning rate on the training process? Which performed best?\n",
        "I tried 11 different learning rate to study its effect to the training process. when learning rate is 0.00075 and 0.001 have the best performance. When learning rate get bigger, the performance becomes worse. when learning rate greater than 0.01, the best accuracy is 0.1. The learning rate and test accuracy are [0.0005, 0.00075, 0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.025, 0.05] and [0.914900004863739, 0.9542199969291687, 0.9473400115966797, 0.936680018901825, 0.929099977016449, 0.9061999917030334, 0.8217999935150146, 0.10000000149011612, 0.6461399793624878, 0.10000000149011612, 0.10000000149011612] respectively.\n",
        "2. I tried 8 different batch size to study its effect to the training process. Basically, the test accuracy increase with the batchsize when batch size is lower than 256. when batch size is 120 and 200 have the best performance. The batch size and test accuracy are [20, 40, 60, 80,100,120,150,200] and [0.9050800204277039, 0.9305599927902222, 0.9078199863433838, 0.9232800006866455, 0.9289799928665161, 0.9401199817657471, 0.9350399971008301, 0.9479600191116333] respectively.\n",
        "3. I tried different hyperparamters and figure out the best performance happens when learning rate = 0.001 and batchsize is 128. The test accuracy is 0.95.\n",
        "4. a. The performance of FF model is much worse than CNN model. the test accuracy is 0.288. \n",
        "b. FF has 31,604 parameters, the Lenet has 697046 parameters. LeNet has more parameters than FF model, but its worth it. The performance of LeNet is much better than FF model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read training and testing data"
      ],
      "metadata": {
        "id": "yatFZqGaYKWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDRFVftrzs6E",
        "outputId": "9691dd30-b88d-45ee-9945-ca8aed89f609"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n",
            "image_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "50000 test samples\n"
          ]
        }
      ],
      "source": [
        "# number of classes\n",
        "n_class = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(image_train, class_train),(image_test, class_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "image_train = image_train.astype(\"float32\") / 255\n",
        "image_test = image_test.astype(\"float32\") / 255\n",
        "\n",
        "#add an additional dimension to represent the single-channel\n",
        "image_train = image_train.reshape(-1, 32, 32, 3) \n",
        "image_test = image_test.reshape(-1, 32, 32, 3)\n",
        "\n",
        "print(\"image_train shape:\", image_train.shape)\n",
        "print(image_train.shape[0], \"train samples\")\n",
        "print(image_train.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "class_train = keras.utils.to_categorical(class_train, n_class)\n",
        "class_test = keras.utils.to_categorical(class_test, n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The effect of learning rate"
      ],
      "metadata": {
        "id": "pAb9xBLmYQvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code to test the effect of learning rate\n",
        "# train the LeNet at 12 different learning rate(its time consuming)\n",
        "\n",
        "lr_list = [0.0005, 0.00075, 0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.025, 0.05]\n",
        "Accuracy = []\n",
        "for lr in lr_list:\n",
        "  # Build a LeNet Convolutional Neural Network\n",
        "\n",
        "  cnn_model = keras.Sequential()\n",
        "  #layer 1-2\n",
        "  cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 3-4\n",
        "  cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 5\n",
        "  cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "  #flatten 2d data to 1d\n",
        "  cnn_model.add(keras.layers.Flatten())\n",
        "  #layer 6\n",
        "  cnn_model.add(keras.layers.Dense(84))\n",
        "  cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "  # layer 7 output layer\n",
        "  cnn_model.add(keras.layers.Dense(n_class))\n",
        "  cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model.build(input_shape=(1,32,32,3))\n",
        "  # print summary of the model\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # train the model\n",
        "  epochs = 25\n",
        "  batch_size = 128\n",
        "\n",
        "  #define the optimizer\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  # compile the model\n",
        "  cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  # train the model\n",
        "  cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  # Evaluate\n",
        "  score = cnn_model.evaluate(image_train, class_train)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "  Accuracy.append(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Swq-IBJ866G",
        "outputId": "1e8c2ab7-2003-4c32-e3e3-67897fed0e5f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (1, 16, 16, 6)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation (Activation)     (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 11s 7ms/step - loss: 1.7002 - accuracy: 0.3853 - val_loss: 1.4676 - val_accuracy: 0.4850\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3767 - accuracy: 0.5101 - val_loss: 1.2919 - val_accuracy: 0.5414\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2487 - accuracy: 0.5576 - val_loss: 1.2121 - val_accuracy: 0.5730\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1633 - accuracy: 0.5875 - val_loss: 1.1395 - val_accuracy: 0.5976\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0855 - accuracy: 0.6203 - val_loss: 1.0754 - val_accuracy: 0.6246\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0206 - accuracy: 0.6413 - val_loss: 1.0684 - val_accuracy: 0.6270\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9632 - accuracy: 0.6653 - val_loss: 1.0380 - val_accuracy: 0.6388\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9091 - accuracy: 0.6825 - val_loss: 1.0055 - val_accuracy: 0.6502\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8611 - accuracy: 0.7013 - val_loss: 1.0258 - val_accuracy: 0.6364\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8170 - accuracy: 0.7166 - val_loss: 0.9766 - val_accuracy: 0.6638\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7696 - accuracy: 0.7326 - val_loss: 0.9526 - val_accuracy: 0.6790\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7244 - accuracy: 0.7493 - val_loss: 0.9498 - val_accuracy: 0.6750\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6787 - accuracy: 0.7648 - val_loss: 1.0210 - val_accuracy: 0.6578\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6321 - accuracy: 0.7794 - val_loss: 0.9639 - val_accuracy: 0.6758\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5863 - accuracy: 0.7984 - val_loss: 0.9745 - val_accuracy: 0.6776\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5443 - accuracy: 0.8106 - val_loss: 1.0306 - val_accuracy: 0.6672\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5102 - accuracy: 0.8230 - val_loss: 0.9938 - val_accuracy: 0.6824\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4659 - accuracy: 0.8400 - val_loss: 1.0344 - val_accuracy: 0.6758\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4217 - accuracy: 0.8560 - val_loss: 1.0884 - val_accuracy: 0.6768\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3866 - accuracy: 0.8677 - val_loss: 1.0899 - val_accuracy: 0.6850\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3535 - accuracy: 0.8780 - val_loss: 1.1784 - val_accuracy: 0.6656\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3075 - accuracy: 0.8978 - val_loss: 1.1595 - val_accuracy: 0.6836\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.2742 - accuracy: 0.9086 - val_loss: 1.2479 - val_accuracy: 0.6768\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2486 - accuracy: 0.9166 - val_loss: 1.3111 - val_accuracy: 0.6718\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.2131 - accuracy: 0.9301 - val_loss: 1.3170 - val_accuracy: 0.6796\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2844 - accuracy: 0.9235\n",
            "Test loss: 0.28441479802131653\n",
            "Test accuracy: 0.9235399961471558\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.6322 - accuracy: 0.4134 - val_loss: 1.3436 - val_accuracy: 0.5172\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2978 - accuracy: 0.5405 - val_loss: 1.2360 - val_accuracy: 0.5642\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1574 - accuracy: 0.5907 - val_loss: 1.1159 - val_accuracy: 0.6058\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0519 - accuracy: 0.6310 - val_loss: 1.0719 - val_accuracy: 0.6206\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9814 - accuracy: 0.6576 - val_loss: 1.0439 - val_accuracy: 0.6360\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9011 - accuracy: 0.6855 - val_loss: 0.9528 - val_accuracy: 0.6762\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8282 - accuracy: 0.7105 - val_loss: 0.9508 - val_accuracy: 0.6754\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7693 - accuracy: 0.7305 - val_loss: 0.9519 - val_accuracy: 0.6726\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7080 - accuracy: 0.7523 - val_loss: 0.9556 - val_accuracy: 0.6812\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6444 - accuracy: 0.7742 - val_loss: 0.9251 - val_accuracy: 0.6884\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5842 - accuracy: 0.7984 - val_loss: 0.9563 - val_accuracy: 0.6850\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5187 - accuracy: 0.8202 - val_loss: 0.9870 - val_accuracy: 0.6858\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4586 - accuracy: 0.8420 - val_loss: 1.0894 - val_accuracy: 0.6786\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3959 - accuracy: 0.8640 - val_loss: 1.0910 - val_accuracy: 0.6750\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3446 - accuracy: 0.8806 - val_loss: 1.1378 - val_accuracy: 0.6852\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2923 - accuracy: 0.9009 - val_loss: 1.1883 - val_accuracy: 0.6786\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.2463 - accuracy: 0.9175 - val_loss: 1.3146 - val_accuracy: 0.6694\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.2044 - accuracy: 0.9314 - val_loss: 1.3882 - val_accuracy: 0.6758\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1707 - accuracy: 0.9436 - val_loss: 1.4900 - val_accuracy: 0.6760\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1382 - accuracy: 0.9553 - val_loss: 1.5628 - val_accuracy: 0.6750\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1175 - accuracy: 0.9623 - val_loss: 1.6791 - val_accuracy: 0.6706\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0978 - accuracy: 0.9687 - val_loss: 1.8270 - val_accuracy: 0.6774\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.1044 - accuracy: 0.9643 - val_loss: 1.8844 - val_accuracy: 0.6678\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0806 - accuracy: 0.9739 - val_loss: 2.0517 - val_accuracy: 0.6570\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0829 - accuracy: 0.9719 - val_loss: 2.0176 - val_accuracy: 0.6648\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2713 - accuracy: 0.9435\n",
            "Test loss: 0.2712860405445099\n",
            "Test accuracy: 0.9435200095176697\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.6518 - accuracy: 0.3992 - val_loss: 1.4400 - val_accuracy: 0.4804\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3425 - accuracy: 0.5230 - val_loss: 1.2551 - val_accuracy: 0.5438\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1680 - accuracy: 0.5896 - val_loss: 1.1052 - val_accuracy: 0.6136\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0562 - accuracy: 0.6298 - val_loss: 1.0505 - val_accuracy: 0.6268\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9580 - accuracy: 0.6650 - val_loss: 0.9890 - val_accuracy: 0.6634\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8639 - accuracy: 0.6988 - val_loss: 0.9786 - val_accuracy: 0.6672\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7975 - accuracy: 0.7216 - val_loss: 0.9417 - val_accuracy: 0.6782\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7222 - accuracy: 0.7487 - val_loss: 0.9466 - val_accuracy: 0.6844\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6544 - accuracy: 0.7733 - val_loss: 0.9341 - val_accuracy: 0.6920\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5859 - accuracy: 0.7960 - val_loss: 0.9787 - val_accuracy: 0.6876\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5195 - accuracy: 0.8205 - val_loss: 1.0148 - val_accuracy: 0.6812\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4514 - accuracy: 0.8444 - val_loss: 1.0199 - val_accuracy: 0.6860\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3905 - accuracy: 0.8650 - val_loss: 1.1264 - val_accuracy: 0.6744\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3312 - accuracy: 0.8863 - val_loss: 1.1529 - val_accuracy: 0.6872\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2804 - accuracy: 0.9038 - val_loss: 1.2816 - val_accuracy: 0.6664\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2319 - accuracy: 0.9200 - val_loss: 1.3439 - val_accuracy: 0.6740\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1924 - accuracy: 0.9350 - val_loss: 1.4441 - val_accuracy: 0.6778\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1573 - accuracy: 0.9466 - val_loss: 1.5962 - val_accuracy: 0.6802\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1266 - accuracy: 0.9570 - val_loss: 1.6621 - val_accuracy: 0.6808\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1207 - accuracy: 0.9578 - val_loss: 1.8048 - val_accuracy: 0.6618\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1059 - accuracy: 0.9645 - val_loss: 1.9788 - val_accuracy: 0.6588\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0964 - accuracy: 0.9678 - val_loss: 2.0158 - val_accuracy: 0.6638\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0967 - accuracy: 0.9667 - val_loss: 2.0921 - val_accuracy: 0.6624\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0865 - accuracy: 0.9702 - val_loss: 2.1837 - val_accuracy: 0.6742\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0750 - accuracy: 0.9740 - val_loss: 2.2144 - val_accuracy: 0.6614\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2748 - accuracy: 0.9496\n",
            "Test loss: 0.2747865319252014\n",
            "Test accuracy: 0.9496200084686279\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.5929 - accuracy: 0.4184 - val_loss: 1.4191 - val_accuracy: 0.4830\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2343 - accuracy: 0.5604 - val_loss: 1.1543 - val_accuracy: 0.5846\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0793 - accuracy: 0.6189 - val_loss: 1.1320 - val_accuracy: 0.5924\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9714 - accuracy: 0.6569 - val_loss: 0.9871 - val_accuracy: 0.6562\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8753 - accuracy: 0.6927 - val_loss: 0.9985 - val_accuracy: 0.6520\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7906 - accuracy: 0.7206 - val_loss: 0.9832 - val_accuracy: 0.6566\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7070 - accuracy: 0.7505 - val_loss: 0.9521 - val_accuracy: 0.6832\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6245 - accuracy: 0.7806 - val_loss: 0.9818 - val_accuracy: 0.6834\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5408 - accuracy: 0.8095 - val_loss: 1.0341 - val_accuracy: 0.6726\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4615 - accuracy: 0.8377 - val_loss: 1.1154 - val_accuracy: 0.6662\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4035 - accuracy: 0.8555 - val_loss: 1.2751 - val_accuracy: 0.6494\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3376 - accuracy: 0.8784 - val_loss: 1.2921 - val_accuracy: 0.6588\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2813 - accuracy: 0.9004 - val_loss: 1.4733 - val_accuracy: 0.6534\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2447 - accuracy: 0.9134 - val_loss: 1.5848 - val_accuracy: 0.6434\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2233 - accuracy: 0.9196 - val_loss: 1.6887 - val_accuracy: 0.6570\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1806 - accuracy: 0.9370 - val_loss: 1.8193 - val_accuracy: 0.6466\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1764 - accuracy: 0.9374 - val_loss: 2.0545 - val_accuracy: 0.6410\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1588 - accuracy: 0.9438 - val_loss: 2.0556 - val_accuracy: 0.6376\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.1402 - accuracy: 0.9504 - val_loss: 2.1280 - val_accuracy: 0.6340\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 0.1552 - accuracy: 0.9450 - val_loss: 2.2690 - val_accuracy: 0.6318\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1259 - accuracy: 0.9560 - val_loss: 2.3967 - val_accuracy: 0.6468\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1292 - accuracy: 0.9554 - val_loss: 2.3794 - val_accuracy: 0.6366\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1120 - accuracy: 0.9618 - val_loss: 2.4071 - val_accuracy: 0.6420\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1255 - accuracy: 0.9566 - val_loss: 2.5384 - val_accuracy: 0.6480\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1178 - accuracy: 0.9591 - val_loss: 2.7333 - val_accuracy: 0.6360\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3612 - accuracy: 0.9343\n",
            "Test loss: 0.3611606955528259\n",
            "Test accuracy: 0.9343400001525879\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.6652 - accuracy: 0.3906 - val_loss: 1.4130 - val_accuracy: 0.4914\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3414 - accuracy: 0.5170 - val_loss: 1.2996 - val_accuracy: 0.5296\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1979 - accuracy: 0.5728 - val_loss: 1.2199 - val_accuracy: 0.5744\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0743 - accuracy: 0.6198 - val_loss: 1.1442 - val_accuracy: 0.5960\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9645 - accuracy: 0.6596 - val_loss: 1.0923 - val_accuracy: 0.6154\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8599 - accuracy: 0.6966 - val_loss: 1.1195 - val_accuracy: 0.6250\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7633 - accuracy: 0.7304 - val_loss: 1.1824 - val_accuracy: 0.6094\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6586 - accuracy: 0.7679 - val_loss: 1.1887 - val_accuracy: 0.6296\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5788 - accuracy: 0.7930 - val_loss: 1.3267 - val_accuracy: 0.6154\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5001 - accuracy: 0.8233 - val_loss: 1.4165 - val_accuracy: 0.6060\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4265 - accuracy: 0.8474 - val_loss: 1.5966 - val_accuracy: 0.6078\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3606 - accuracy: 0.8712 - val_loss: 1.7638 - val_accuracy: 0.6068\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3112 - accuracy: 0.8895 - val_loss: 1.9334 - val_accuracy: 0.5942\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2861 - accuracy: 0.8989 - val_loss: 2.0387 - val_accuracy: 0.5916\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2547 - accuracy: 0.9090 - val_loss: 2.1886 - val_accuracy: 0.6052\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2225 - accuracy: 0.9226 - val_loss: 2.4318 - val_accuracy: 0.5816\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2004 - accuracy: 0.9295 - val_loss: 2.4607 - val_accuracy: 0.5976\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1890 - accuracy: 0.9350 - val_loss: 2.5424 - val_accuracy: 0.6026\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1830 - accuracy: 0.9361 - val_loss: 2.7659 - val_accuracy: 0.5926\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1723 - accuracy: 0.9394 - val_loss: 2.7195 - val_accuracy: 0.5940\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1841 - accuracy: 0.9376 - val_loss: 2.8377 - val_accuracy: 0.5732\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1596 - accuracy: 0.9456 - val_loss: 2.8267 - val_accuracy: 0.5946\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1585 - accuracy: 0.9459 - val_loss: 2.8816 - val_accuracy: 0.5870\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1421 - accuracy: 0.9532 - val_loss: 3.1781 - val_accuracy: 0.5972\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1481 - accuracy: 0.9494 - val_loss: 3.1334 - val_accuracy: 0.5942\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3918 - accuracy: 0.9325\n",
            "Test loss: 0.39182889461517334\n",
            "Test accuracy: 0.932479977607727\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.7824 - accuracy: 0.3371 - val_loss: 1.4939 - val_accuracy: 0.4454\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4168 - accuracy: 0.4878 - val_loss: 1.3334 - val_accuracy: 0.5174\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2828 - accuracy: 0.5385 - val_loss: 1.3380 - val_accuracy: 0.5300\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2134 - accuracy: 0.5638 - val_loss: 1.2180 - val_accuracy: 0.5670\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1566 - accuracy: 0.5879 - val_loss: 1.2392 - val_accuracy: 0.5640\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1168 - accuracy: 0.6023 - val_loss: 1.1916 - val_accuracy: 0.5832\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0736 - accuracy: 0.6150 - val_loss: 1.1694 - val_accuracy: 0.5878\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0340 - accuracy: 0.6339 - val_loss: 1.1476 - val_accuracy: 0.6038\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0000 - accuracy: 0.6423 - val_loss: 1.2120 - val_accuracy: 0.5790\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9673 - accuracy: 0.6557 - val_loss: 1.2161 - val_accuracy: 0.5822\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9447 - accuracy: 0.6635 - val_loss: 1.2272 - val_accuracy: 0.5844\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9121 - accuracy: 0.6743 - val_loss: 1.2604 - val_accuracy: 0.5708\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8901 - accuracy: 0.6833 - val_loss: 1.2286 - val_accuracy: 0.5982\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8595 - accuracy: 0.6930 - val_loss: 1.2193 - val_accuracy: 0.5972\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8436 - accuracy: 0.6997 - val_loss: 1.2494 - val_accuracy: 0.5858\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8162 - accuracy: 0.7094 - val_loss: 1.3172 - val_accuracy: 0.5700\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7895 - accuracy: 0.7195 - val_loss: 1.3256 - val_accuracy: 0.5762\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7786 - accuracy: 0.7214 - val_loss: 1.3270 - val_accuracy: 0.5800\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7518 - accuracy: 0.7330 - val_loss: 1.3248 - val_accuracy: 0.5838\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7306 - accuracy: 0.7378 - val_loss: 1.3953 - val_accuracy: 0.5770\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7067 - accuracy: 0.7463 - val_loss: 1.4532 - val_accuracy: 0.5792\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6865 - accuracy: 0.7538 - val_loss: 1.4877 - val_accuracy: 0.5690\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6731 - accuracy: 0.7580 - val_loss: 1.5368 - val_accuracy: 0.5756\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6381 - accuracy: 0.7713 - val_loss: 1.5600 - val_accuracy: 0.5726\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6239 - accuracy: 0.7763 - val_loss: 1.5708 - val_accuracy: 0.5596\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6317 - accuracy: 0.7892\n",
            "Test loss: 0.6316714882850647\n",
            "Test accuracy: 0.7892199754714966\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_12 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_13 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.8986 - accuracy: 0.2978 - val_loss: 1.6280 - val_accuracy: 0.3916\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.5123 - accuracy: 0.4490 - val_loss: 1.4138 - val_accuracy: 0.4844\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3514 - accuracy: 0.5125 - val_loss: 1.2867 - val_accuracy: 0.5310\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2648 - accuracy: 0.5462 - val_loss: 1.2505 - val_accuracy: 0.5452\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1772 - accuracy: 0.5782 - val_loss: 1.2401 - val_accuracy: 0.5622\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1131 - accuracy: 0.6043 - val_loss: 1.1688 - val_accuracy: 0.5824\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0567 - accuracy: 0.6237 - val_loss: 1.2230 - val_accuracy: 0.5740\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0133 - accuracy: 0.6416 - val_loss: 1.1957 - val_accuracy: 0.5926\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9546 - accuracy: 0.6586 - val_loss: 1.1928 - val_accuracy: 0.5856\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9023 - accuracy: 0.6791 - val_loss: 1.2081 - val_accuracy: 0.5984\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8614 - accuracy: 0.6933 - val_loss: 1.2925 - val_accuracy: 0.5712\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8241 - accuracy: 0.7069 - val_loss: 1.2709 - val_accuracy: 0.5972\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7694 - accuracy: 0.7258 - val_loss: 1.2792 - val_accuracy: 0.5820\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7379 - accuracy: 0.7384 - val_loss: 1.3434 - val_accuracy: 0.5938\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7027 - accuracy: 0.7508 - val_loss: 1.4281 - val_accuracy: 0.5808\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6694 - accuracy: 0.7598 - val_loss: 1.4429 - val_accuracy: 0.5846\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6284 - accuracy: 0.7744 - val_loss: 1.4980 - val_accuracy: 0.5896\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6006 - accuracy: 0.7847 - val_loss: 1.4800 - val_accuracy: 0.5968\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5705 - accuracy: 0.7950 - val_loss: 1.5702 - val_accuracy: 0.5806\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5324 - accuracy: 0.8089 - val_loss: 1.7064 - val_accuracy: 0.5786\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5146 - accuracy: 0.8161 - val_loss: 1.8189 - val_accuracy: 0.5730\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4830 - accuracy: 0.8264 - val_loss: 1.8312 - val_accuracy: 0.5658\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4788 - accuracy: 0.8281 - val_loss: 1.9854 - val_accuracy: 0.5660\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4452 - accuracy: 0.8413 - val_loss: 2.0156 - val_accuracy: 0.5624\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4443 - accuracy: 0.8432 - val_loss: 2.1631 - val_accuracy: 0.5622\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5377 - accuracy: 0.8415\n",
            "Test loss: 0.5377292037010193\n",
            "Test accuracy: 0.8414999842643738\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 2.0505 - accuracy: 0.2373 - val_loss: 1.7884 - val_accuracy: 0.3534\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.7551 - accuracy: 0.3600 - val_loss: 1.6600 - val_accuracy: 0.3948\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.6257 - accuracy: 0.4133 - val_loss: 1.5434 - val_accuracy: 0.4400\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.5461 - accuracy: 0.4415 - val_loss: 1.5324 - val_accuracy: 0.4634\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4748 - accuracy: 0.4707 - val_loss: 1.4747 - val_accuracy: 0.4782\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4383 - accuracy: 0.4868 - val_loss: 1.4586 - val_accuracy: 0.4870\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3943 - accuracy: 0.4992 - val_loss: 1.4307 - val_accuracy: 0.4914\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3651 - accuracy: 0.5121 - val_loss: 1.5322 - val_accuracy: 0.4704\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3465 - accuracy: 0.5206 - val_loss: 1.4286 - val_accuracy: 0.4944\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3255 - accuracy: 0.5266 - val_loss: 1.4576 - val_accuracy: 0.4878\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2998 - accuracy: 0.5356 - val_loss: 1.4449 - val_accuracy: 0.4880\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 1.2947 - accuracy: 0.5381 - val_loss: 1.4904 - val_accuracy: 0.4854\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2774 - accuracy: 0.5419 - val_loss: 1.4774 - val_accuracy: 0.4962\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2669 - accuracy: 0.5452 - val_loss: 1.4527 - val_accuracy: 0.4984\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2453 - accuracy: 0.5575 - val_loss: 1.4667 - val_accuracy: 0.4964\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2433 - accuracy: 0.5551 - val_loss: 1.4647 - val_accuracy: 0.4922\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2312 - accuracy: 0.5594 - val_loss: 1.4901 - val_accuracy: 0.4956\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2274 - accuracy: 0.5616 - val_loss: 1.4870 - val_accuracy: 0.5014\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2229 - accuracy: 0.5646 - val_loss: 1.5434 - val_accuracy: 0.4744\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2204 - accuracy: 0.5632 - val_loss: 1.4992 - val_accuracy: 0.4926\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2085 - accuracy: 0.5665 - val_loss: 1.4799 - val_accuracy: 0.4958\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2041 - accuracy: 0.5695 - val_loss: 1.5387 - val_accuracy: 0.4856\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1836 - accuracy: 0.5754 - val_loss: 1.5137 - val_accuracy: 0.4944\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1865 - accuracy: 0.5747 - val_loss: 1.5361 - val_accuracy: 0.4884\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1759 - accuracy: 0.5803 - val_loss: 1.5163 - val_accuracy: 0.5038\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1422 - accuracy: 0.5953\n",
            "Test loss: 1.1421693563461304\n",
            "Test accuracy: 0.5952600240707397\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_16 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 2.3111 - accuracy: 0.0990 - val_loss: 2.3035 - val_accuracy: 0.0950\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1004 - val_loss: 2.3031 - val_accuracy: 0.0976\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.1016 - val_loss: 2.3033 - val_accuracy: 0.1038\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0970 - val_loss: 2.3037 - val_accuracy: 0.0970\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0998 - val_loss: 2.3037 - val_accuracy: 0.0976\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3035 - accuracy: 0.0988 - val_loss: 2.3038 - val_accuracy: 0.0950\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1007 - val_loss: 2.3036 - val_accuracy: 0.0958\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0953 - val_loss: 2.3035 - val_accuracy: 0.0958\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0989 - val_loss: 2.3022 - val_accuracy: 0.1058\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0983 - val_loss: 2.3031 - val_accuracy: 0.0976\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.1027 - val_loss: 2.3031 - val_accuracy: 0.1064\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.1038\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.1004 - val_loss: 2.3035 - val_accuracy: 0.0958\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0996 - val_loss: 2.3028 - val_accuracy: 0.1038\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.1038\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1000 - val_loss: 2.3038 - val_accuracy: 0.0976\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3036 - accuracy: 0.0988 - val_loss: 2.3036 - val_accuracy: 0.0976\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1001 - val_loss: 2.3033 - val_accuracy: 0.1024\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1015 - val_loss: 2.3028 - val_accuracy: 0.0976\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0998 - val_loss: 2.3034 - val_accuracy: 0.0958\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0990 - val_loss: 2.3042 - val_accuracy: 0.0986\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.1024\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0994 - val_loss: 2.3039 - val_accuracy: 0.0970\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3034 - accuracy: 0.0992 - val_loss: 2.3032 - val_accuracy: 0.0976\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0988 - val_loss: 2.3030 - val_accuracy: 0.0976\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3028 - accuracy: 0.1000\n",
            "Test loss: 2.3028433322906494\n",
            "Test accuracy: 0.10000000149011612\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_18 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_19 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 2.6534 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1064\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3039 - accuracy: 0.1008 - val_loss: 2.3035 - val_accuracy: 0.1064\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1007 - val_loss: 2.3054 - val_accuracy: 0.0976\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0997 - val_loss: 2.3039 - val_accuracy: 0.0950\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0999 - val_loss: 2.3049 - val_accuracy: 0.0986\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.0990 - val_loss: 2.3025 - val_accuracy: 0.1064\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.0990 - val_loss: 2.3057 - val_accuracy: 0.0970\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.1029 - val_loss: 2.3034 - val_accuracy: 0.0986\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0998 - val_loss: 2.3040 - val_accuracy: 0.1038\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1011 - val_loss: 2.3035 - val_accuracy: 0.1024\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1028 - val_loss: 2.3030 - val_accuracy: 0.1038\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.1010 - val_loss: 2.3051 - val_accuracy: 0.0976\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3040 - accuracy: 0.0987 - val_loss: 2.3059 - val_accuracy: 0.0958\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.0994 - val_loss: 2.3035 - val_accuracy: 0.1038\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3044 - accuracy: 0.0981 - val_loss: 2.3049 - val_accuracy: 0.0986\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.1003 - val_loss: 2.3058 - val_accuracy: 0.0950\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3040 - accuracy: 0.1011 - val_loss: 2.3040 - val_accuracy: 0.0970\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0999 - val_loss: 2.3079 - val_accuracy: 0.0958\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3045 - accuracy: 0.0996 - val_loss: 2.3034 - val_accuracy: 0.1038\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0979 - val_loss: 2.3031 - val_accuracy: 0.0950\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.0976 - val_loss: 2.3064 - val_accuracy: 0.0950\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.0992 - val_loss: 2.3041 - val_accuracy: 0.0976\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3045 - accuracy: 0.0985 - val_loss: 2.3030 - val_accuracy: 0.0970\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.1008 - val_loss: 2.3036 - val_accuracy: 0.1064\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.0993 - val_loss: 2.3040 - val_accuracy: 0.0950\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.1000\n",
            "Test loss: 2.303091049194336\n",
            "Test accuracy: 0.10000000149011612\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_20 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 2.3823 - accuracy: 0.0991 - val_loss: 2.3069 - val_accuracy: 0.1024\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3056 - accuracy: 0.0989 - val_loss: 2.3039 - val_accuracy: 0.1038\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.0985 - val_loss: 2.3061 - val_accuracy: 0.0958\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.1000 - val_loss: 2.3043 - val_accuracy: 0.1024\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 2.3060 - accuracy: 0.1018 - val_loss: 2.3032 - val_accuracy: 0.1064\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 3s 9ms/step - loss: 2.3055 - accuracy: 0.0990 - val_loss: 2.3050 - val_accuracy: 0.0986\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3053 - accuracy: 0.0996 - val_loss: 2.3067 - val_accuracy: 0.1064\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3060 - accuracy: 0.0989 - val_loss: 2.3056 - val_accuracy: 0.0950\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1014 - val_loss: 2.3038 - val_accuracy: 0.1058\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.0984 - val_loss: 2.3064 - val_accuracy: 0.0958\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3061 - accuracy: 0.0999 - val_loss: 2.3039 - val_accuracy: 0.0986\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3062 - accuracy: 0.1002 - val_loss: 2.3039 - val_accuracy: 0.0976\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3065 - accuracy: 0.0959 - val_loss: 2.3063 - val_accuracy: 0.1058\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.0979 - val_loss: 2.3083 - val_accuracy: 0.0976\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3060 - accuracy: 0.0978 - val_loss: 2.3041 - val_accuracy: 0.1064\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.0998 - val_loss: 2.3065 - val_accuracy: 0.0970\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3062 - accuracy: 0.0980 - val_loss: 2.3035 - val_accuracy: 0.0976\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.1006 - val_loss: 2.3032 - val_accuracy: 0.0976\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.0963 - val_loss: 2.3063 - val_accuracy: 0.1024\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.0986 - val_loss: 2.3047 - val_accuracy: 0.0976\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3060 - accuracy: 0.0978 - val_loss: 2.3046 - val_accuracy: 0.0976\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.1002 - val_loss: 2.3058 - val_accuracy: 0.1058\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3064 - accuracy: 0.1002 - val_loss: 2.3076 - val_accuracy: 0.0986\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3068 - accuracy: 0.0975 - val_loss: 2.3061 - val_accuracy: 0.0958\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.0994 - val_loss: 2.3062 - val_accuracy: 0.0986\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3075 - accuracy: 0.1000\n",
            "Test loss: 2.307508707046509\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the accuracy of different learning rate\n",
        "a = range(len(lr_list))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(a, Accuracy, \"*\")\n",
        "#plt.scatter(a, Accuracy)\n",
        "\n",
        "ax.set_xticks(a)\n",
        "ax.set_xticklabels(lr_list)\n",
        "\n",
        "plt.xlabel('learning rate')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('The effect of learning rate')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "B4DPESC6HH3R",
        "outputId": "d7f2a849-09e3-402a-90c3-daa64dba17ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The effect of batch size"
      ],
      "metadata": {
        "id": "kCzv_dssYZXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The code to test the effect of batch size\n",
        "# train the LeNet at 12 different batch size(its time consuming)\n",
        "\n",
        "batchsize_list = [20, 40, 60, 80,100,120,150,200]\n",
        "\n",
        "lr = 0.002\n",
        "Accuracy2 = []\n",
        "for batch_size in batchsize_list:\n",
        "  # Build a LeNet Convolutional Neural Network\n",
        "\n",
        "  cnn_model = keras.Sequential()\n",
        "  #layer 1-2\n",
        "  cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 3-4\n",
        "  cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 5\n",
        "  cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "  #flatten 2d data to 1d\n",
        "  cnn_model.add(keras.layers.Flatten())\n",
        "  #layer 6\n",
        "  cnn_model.add(keras.layers.Dense(84))\n",
        "  cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "  # layer 7 output layer\n",
        "  cnn_model.add(keras.layers.Dense(n_class))\n",
        "  cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model.build(input_shape=(1,32,32,3))\n",
        "  # print summary of the model\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # train the model\n",
        "  epochs = 25\n",
        "  #batch_size = 128\n",
        "\n",
        "  #define the optimizer\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  # compile the model\n",
        "  cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  # train the model\n",
        "  cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  # Evaluate\n",
        "  score = cnn_model.evaluate(image_train, class_train)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "  Accuracy2.append(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpzDTEHVODrl",
        "outputId": "ab1afda2-03fe-49ee-ac31-1d97cf6d5f67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_33 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_22 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2250/2250 [==============================] - 13s 5ms/step - loss: 1.6041 - accuracy: 0.4147 - val_loss: 1.3286 - val_accuracy: 0.5248\n",
            "Epoch 2/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.2610 - accuracy: 0.5524 - val_loss: 1.2778 - val_accuracy: 0.5488\n",
            "Epoch 3/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 1.1356 - accuracy: 0.5968 - val_loss: 1.1429 - val_accuracy: 0.5930\n",
            "Epoch 4/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 1.0394 - accuracy: 0.6320 - val_loss: 1.1734 - val_accuracy: 0.5890\n",
            "Epoch 5/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.9542 - accuracy: 0.6636 - val_loss: 1.1427 - val_accuracy: 0.6108\n",
            "Epoch 6/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.8821 - accuracy: 0.6896 - val_loss: 1.1555 - val_accuracy: 0.6104\n",
            "Epoch 7/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.8097 - accuracy: 0.7143 - val_loss: 1.1934 - val_accuracy: 0.6094\n",
            "Epoch 8/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.7388 - accuracy: 0.7410 - val_loss: 1.2840 - val_accuracy: 0.5956\n",
            "Epoch 9/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.6771 - accuracy: 0.7612 - val_loss: 1.3115 - val_accuracy: 0.5936\n",
            "Epoch 10/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.6113 - accuracy: 0.7849 - val_loss: 1.4684 - val_accuracy: 0.5960\n",
            "Epoch 11/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.5658 - accuracy: 0.7996 - val_loss: 1.5321 - val_accuracy: 0.6010\n",
            "Epoch 12/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.5085 - accuracy: 0.8203 - val_loss: 1.5360 - val_accuracy: 0.5842\n",
            "Epoch 13/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.4658 - accuracy: 0.8341 - val_loss: 1.6819 - val_accuracy: 0.5978\n",
            "Epoch 14/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.4334 - accuracy: 0.8462 - val_loss: 1.8479 - val_accuracy: 0.5816\n",
            "Epoch 15/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.3939 - accuracy: 0.8625 - val_loss: 1.9444 - val_accuracy: 0.5764\n",
            "Epoch 16/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.3745 - accuracy: 0.8670 - val_loss: 1.9773 - val_accuracy: 0.5890\n",
            "Epoch 17/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.3486 - accuracy: 0.8792 - val_loss: 2.2710 - val_accuracy: 0.5732\n",
            "Epoch 18/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3284 - accuracy: 0.8852 - val_loss: 2.2944 - val_accuracy: 0.5680\n",
            "Epoch 19/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.3167 - accuracy: 0.8919 - val_loss: 2.5045 - val_accuracy: 0.5698\n",
            "Epoch 20/25\n",
            "2250/2250 [==============================] - 8s 4ms/step - loss: 0.3017 - accuracy: 0.8964 - val_loss: 2.4759 - val_accuracy: 0.5812\n",
            "Epoch 21/25\n",
            "2250/2250 [==============================] - 11s 5ms/step - loss: 0.2851 - accuracy: 0.9024 - val_loss: 2.5974 - val_accuracy: 0.5634\n",
            "Epoch 22/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2735 - accuracy: 0.9075 - val_loss: 2.7060 - val_accuracy: 0.5786\n",
            "Epoch 23/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2627 - accuracy: 0.9114 - val_loss: 2.6466 - val_accuracy: 0.5712\n",
            "Epoch 24/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2560 - accuracy: 0.9140 - val_loss: 2.8033 - val_accuracy: 0.5712\n",
            "Epoch 25/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2384 - accuracy: 0.9196 - val_loss: 2.8441 - val_accuracy: 0.5802\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4387 - accuracy: 0.9051\n",
            "Test loss: 0.43869543075561523\n",
            "Test accuracy: 0.9050800204277039\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_24 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_25 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1125/1125 [==============================] - 6s 4ms/step - loss: 1.5361 - accuracy: 0.4394 - val_loss: 1.2900 - val_accuracy: 0.5330\n",
            "Epoch 2/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 1.1869 - accuracy: 0.5777 - val_loss: 1.1134 - val_accuracy: 0.6102\n",
            "Epoch 3/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 1.0210 - accuracy: 0.6394 - val_loss: 1.0502 - val_accuracy: 0.6346\n",
            "Epoch 4/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.8861 - accuracy: 0.6879 - val_loss: 1.0222 - val_accuracy: 0.6466\n",
            "Epoch 5/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.7745 - accuracy: 0.7279 - val_loss: 1.0557 - val_accuracy: 0.6458\n",
            "Epoch 6/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.6655 - accuracy: 0.7640 - val_loss: 1.1172 - val_accuracy: 0.6446\n",
            "Epoch 7/25\n",
            "1125/1125 [==============================] - 4s 4ms/step - loss: 0.5610 - accuracy: 0.8026 - val_loss: 1.2374 - val_accuracy: 0.6296\n",
            "Epoch 8/25\n",
            "1125/1125 [==============================] - 4s 4ms/step - loss: 0.4825 - accuracy: 0.8286 - val_loss: 1.3168 - val_accuracy: 0.6354\n",
            "Epoch 9/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.4083 - accuracy: 0.8564 - val_loss: 1.4573 - val_accuracy: 0.6320\n",
            "Epoch 10/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.3526 - accuracy: 0.8738 - val_loss: 1.5703 - val_accuracy: 0.6360\n",
            "Epoch 11/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.3041 - accuracy: 0.8927 - val_loss: 1.6601 - val_accuracy: 0.6348\n",
            "Epoch 12/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2669 - accuracy: 0.9057 - val_loss: 1.7993 - val_accuracy: 0.6234\n",
            "Epoch 13/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2584 - accuracy: 0.9106 - val_loss: 1.8707 - val_accuracy: 0.6296\n",
            "Epoch 14/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2383 - accuracy: 0.9175 - val_loss: 2.3425 - val_accuracy: 0.6148\n",
            "Epoch 15/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2085 - accuracy: 0.9266 - val_loss: 2.2623 - val_accuracy: 0.6244\n",
            "Epoch 16/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1930 - accuracy: 0.9346 - val_loss: 2.3622 - val_accuracy: 0.6246\n",
            "Epoch 17/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1968 - accuracy: 0.9334 - val_loss: 2.5998 - val_accuracy: 0.6184\n",
            "Epoch 18/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1840 - accuracy: 0.9384 - val_loss: 2.4496 - val_accuracy: 0.6264\n",
            "Epoch 19/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1816 - accuracy: 0.9400 - val_loss: 2.6334 - val_accuracy: 0.6224\n",
            "Epoch 20/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1711 - accuracy: 0.9441 - val_loss: 2.7915 - val_accuracy: 0.5984\n",
            "Epoch 21/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1551 - accuracy: 0.9481 - val_loss: 2.8717 - val_accuracy: 0.6238\n",
            "Epoch 22/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1636 - accuracy: 0.9468 - val_loss: 2.7780 - val_accuracy: 0.6208\n",
            "Epoch 23/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1514 - accuracy: 0.9510 - val_loss: 2.9015 - val_accuracy: 0.6224\n",
            "Epoch 24/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1446 - accuracy: 0.9531 - val_loss: 3.2419 - val_accuracy: 0.6052\n",
            "Epoch 25/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1656 - accuracy: 0.9469 - val_loss: 3.0393 - val_accuracy: 0.6164\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3972 - accuracy: 0.9306\n",
            "Test loss: 0.3971517086029053\n",
            "Test accuracy: 0.9305599927902222\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_39 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_26 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 1.6182 - accuracy: 0.4135 - val_loss: 1.3911 - val_accuracy: 0.5062\n",
            "Epoch 2/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1.2824 - accuracy: 0.5430 - val_loss: 1.1764 - val_accuracy: 0.5820\n",
            "Epoch 3/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1.1257 - accuracy: 0.6002 - val_loss: 1.1087 - val_accuracy: 0.6100\n",
            "Epoch 4/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1.0252 - accuracy: 0.6380 - val_loss: 1.0227 - val_accuracy: 0.6416\n",
            "Epoch 5/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.9335 - accuracy: 0.6697 - val_loss: 1.0293 - val_accuracy: 0.6394\n",
            "Epoch 6/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.8650 - accuracy: 0.6946 - val_loss: 1.0236 - val_accuracy: 0.6532\n",
            "Epoch 7/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.7979 - accuracy: 0.7187 - val_loss: 1.0361 - val_accuracy: 0.6514\n",
            "Epoch 8/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.7385 - accuracy: 0.7371 - val_loss: 1.0330 - val_accuracy: 0.6568\n",
            "Epoch 9/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.6714 - accuracy: 0.7646 - val_loss: 1.1158 - val_accuracy: 0.6388\n",
            "Epoch 10/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.6193 - accuracy: 0.7782 - val_loss: 1.1256 - val_accuracy: 0.6480\n",
            "Epoch 11/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5584 - accuracy: 0.7997 - val_loss: 1.2438 - val_accuracy: 0.6442\n",
            "Epoch 12/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5144 - accuracy: 0.8154 - val_loss: 1.2244 - val_accuracy: 0.6464\n",
            "Epoch 13/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4634 - accuracy: 0.8334 - val_loss: 1.4018 - val_accuracy: 0.6214\n",
            "Epoch 14/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4115 - accuracy: 0.8510 - val_loss: 1.4962 - val_accuracy: 0.6284\n",
            "Epoch 15/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3778 - accuracy: 0.8658 - val_loss: 1.5759 - val_accuracy: 0.6308\n",
            "Epoch 16/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3384 - accuracy: 0.8792 - val_loss: 1.5972 - val_accuracy: 0.6250\n",
            "Epoch 17/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3074 - accuracy: 0.8894 - val_loss: 1.8081 - val_accuracy: 0.6246\n",
            "Epoch 18/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2761 - accuracy: 0.9026 - val_loss: 1.8735 - val_accuracy: 0.6118\n",
            "Epoch 19/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2500 - accuracy: 0.9107 - val_loss: 2.1616 - val_accuracy: 0.6342\n",
            "Epoch 20/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2515 - accuracy: 0.9104 - val_loss: 2.0941 - val_accuracy: 0.6134\n",
            "Epoch 21/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2288 - accuracy: 0.9205 - val_loss: 2.1862 - val_accuracy: 0.6118\n",
            "Epoch 22/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2111 - accuracy: 0.9258 - val_loss: 2.2884 - val_accuracy: 0.6222\n",
            "Epoch 23/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2076 - accuracy: 0.9287 - val_loss: 2.3629 - val_accuracy: 0.6118\n",
            "Epoch 24/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1979 - accuracy: 0.9323 - val_loss: 2.4731 - val_accuracy: 0.6202\n",
            "Epoch 25/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1692 - accuracy: 0.9415 - val_loss: 2.6410 - val_accuracy: 0.6214\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4208 - accuracy: 0.9078\n",
            "Test loss: 0.4207651615142822\n",
            "Test accuracy: 0.9078199863433838\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_28 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "563/563 [==============================] - 4s 6ms/step - loss: 1.5872 - accuracy: 0.4190 - val_loss: 1.2968 - val_accuracy: 0.5318\n",
            "Epoch 2/25\n",
            "563/563 [==============================] - 5s 8ms/step - loss: 1.2005 - accuracy: 0.5760 - val_loss: 1.1304 - val_accuracy: 0.5914\n",
            "Epoch 3/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 1.0461 - accuracy: 0.6301 - val_loss: 1.0214 - val_accuracy: 0.6418\n",
            "Epoch 4/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.9366 - accuracy: 0.6697 - val_loss: 1.0094 - val_accuracy: 0.6472\n",
            "Epoch 5/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.8502 - accuracy: 0.7009 - val_loss: 0.9731 - val_accuracy: 0.6666\n",
            "Epoch 6/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.7672 - accuracy: 0.7290 - val_loss: 0.9915 - val_accuracy: 0.6708\n",
            "Epoch 7/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.6886 - accuracy: 0.7568 - val_loss: 0.9998 - val_accuracy: 0.6720\n",
            "Epoch 8/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.6196 - accuracy: 0.7799 - val_loss: 1.0278 - val_accuracy: 0.6658\n",
            "Epoch 9/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.5477 - accuracy: 0.8061 - val_loss: 1.1133 - val_accuracy: 0.6598\n",
            "Epoch 10/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.4836 - accuracy: 0.8268 - val_loss: 1.1835 - val_accuracy: 0.6490\n",
            "Epoch 11/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.4346 - accuracy: 0.8441 - val_loss: 1.2297 - val_accuracy: 0.6550\n",
            "Epoch 12/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.3736 - accuracy: 0.8668 - val_loss: 1.4376 - val_accuracy: 0.6510\n",
            "Epoch 13/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.3345 - accuracy: 0.8809 - val_loss: 1.5256 - val_accuracy: 0.6524\n",
            "Epoch 14/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2851 - accuracy: 0.8987 - val_loss: 1.6284 - val_accuracy: 0.6432\n",
            "Epoch 15/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2746 - accuracy: 0.9019 - val_loss: 1.6672 - val_accuracy: 0.6428\n",
            "Epoch 16/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2328 - accuracy: 0.9158 - val_loss: 1.8845 - val_accuracy: 0.6414\n",
            "Epoch 17/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2168 - accuracy: 0.9222 - val_loss: 2.0091 - val_accuracy: 0.6450\n",
            "Epoch 18/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1965 - accuracy: 0.9311 - val_loss: 2.1334 - val_accuracy: 0.6440\n",
            "Epoch 19/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1821 - accuracy: 0.9352 - val_loss: 2.3774 - val_accuracy: 0.6436\n",
            "Epoch 20/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1839 - accuracy: 0.9357 - val_loss: 2.3336 - val_accuracy: 0.6370\n",
            "Epoch 21/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1581 - accuracy: 0.9451 - val_loss: 2.3527 - val_accuracy: 0.6406\n",
            "Epoch 22/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1755 - accuracy: 0.9401 - val_loss: 2.4317 - val_accuracy: 0.6438\n",
            "Epoch 23/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1323 - accuracy: 0.9541 - val_loss: 2.7906 - val_accuracy: 0.6336\n",
            "Epoch 24/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1337 - accuracy: 0.9541 - val_loss: 2.7010 - val_accuracy: 0.6420\n",
            "Epoch 25/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1527 - accuracy: 0.9481 - val_loss: 2.7658 - val_accuracy: 0.6274\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3909 - accuracy: 0.9233\n",
            "Test loss: 0.3909228444099426\n",
            "Test accuracy: 0.9232800006866455\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_45 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_30 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_31 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "450/450 [==============================] - 3s 5ms/step - loss: 1.5631 - accuracy: 0.4341 - val_loss: 1.2131 - val_accuracy: 0.5696\n",
            "Epoch 2/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 1.1736 - accuracy: 0.5833 - val_loss: 1.0720 - val_accuracy: 0.6206\n",
            "Epoch 3/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 1.0109 - accuracy: 0.6438 - val_loss: 1.0446 - val_accuracy: 0.6232\n",
            "Epoch 4/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.8668 - accuracy: 0.6949 - val_loss: 0.9836 - val_accuracy: 0.6658\n",
            "Epoch 5/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.7531 - accuracy: 0.7361 - val_loss: 1.0000 - val_accuracy: 0.6638\n",
            "Epoch 6/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.6412 - accuracy: 0.7748 - val_loss: 1.0080 - val_accuracy: 0.6750\n",
            "Epoch 7/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.5398 - accuracy: 0.8094 - val_loss: 1.0371 - val_accuracy: 0.6748\n",
            "Epoch 8/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.4400 - accuracy: 0.8435 - val_loss: 1.1802 - val_accuracy: 0.6600\n",
            "Epoch 9/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.3556 - accuracy: 0.8737 - val_loss: 1.2798 - val_accuracy: 0.6718\n",
            "Epoch 10/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2840 - accuracy: 0.9006 - val_loss: 1.4172 - val_accuracy: 0.6620\n",
            "Epoch 11/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2317 - accuracy: 0.9183 - val_loss: 1.5712 - val_accuracy: 0.6514\n",
            "Epoch 12/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2060 - accuracy: 0.9260 - val_loss: 1.6786 - val_accuracy: 0.6686\n",
            "Epoch 13/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1638 - accuracy: 0.9432 - val_loss: 1.8183 - val_accuracy: 0.6496\n",
            "Epoch 14/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1521 - accuracy: 0.9462 - val_loss: 2.1245 - val_accuracy: 0.6488\n",
            "Epoch 15/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1520 - accuracy: 0.9483 - val_loss: 2.0495 - val_accuracy: 0.6356\n",
            "Epoch 16/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1346 - accuracy: 0.9533 - val_loss: 2.2671 - val_accuracy: 0.6514\n",
            "Epoch 17/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1322 - accuracy: 0.9543 - val_loss: 2.3655 - val_accuracy: 0.6560\n",
            "Epoch 18/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1262 - accuracy: 0.9576 - val_loss: 2.4755 - val_accuracy: 0.6474\n",
            "Epoch 19/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1153 - accuracy: 0.9606 - val_loss: 2.6272 - val_accuracy: 0.6502\n",
            "Epoch 20/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0936 - accuracy: 0.9692 - val_loss: 2.4994 - val_accuracy: 0.6386\n",
            "Epoch 21/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1211 - accuracy: 0.9596 - val_loss: 2.7009 - val_accuracy: 0.6488\n",
            "Epoch 22/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1040 - accuracy: 0.9645 - val_loss: 2.7413 - val_accuracy: 0.6552\n",
            "Epoch 23/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0865 - accuracy: 0.9710 - val_loss: 2.8114 - val_accuracy: 0.6526\n",
            "Epoch 24/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1034 - accuracy: 0.9662 - val_loss: 2.8127 - val_accuracy: 0.6592\n",
            "Epoch 25/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.0880 - accuracy: 0.9721 - val_loss: 3.0670 - val_accuracy: 0.6354\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4127 - accuracy: 0.9290\n",
            "Test loss: 0.41267773509025574\n",
            "Test accuracy: 0.9289799928665161\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_32 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_33 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.6128 - accuracy: 0.4136 - val_loss: 1.3149 - val_accuracy: 0.5246\n",
            "Epoch 2/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2254 - accuracy: 0.5646 - val_loss: 1.1170 - val_accuracy: 0.6036\n",
            "Epoch 3/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0503 - accuracy: 0.6305 - val_loss: 1.0470 - val_accuracy: 0.6248\n",
            "Epoch 4/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.9157 - accuracy: 0.6808 - val_loss: 0.9852 - val_accuracy: 0.6530\n",
            "Epoch 5/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8123 - accuracy: 0.7174 - val_loss: 0.9625 - val_accuracy: 0.6730\n",
            "Epoch 6/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7046 - accuracy: 0.7510 - val_loss: 0.9896 - val_accuracy: 0.6612\n",
            "Epoch 7/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6129 - accuracy: 0.7827 - val_loss: 1.0033 - val_accuracy: 0.6692\n",
            "Epoch 8/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5106 - accuracy: 0.8209 - val_loss: 1.1090 - val_accuracy: 0.6602\n",
            "Epoch 9/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4367 - accuracy: 0.8450 - val_loss: 1.1817 - val_accuracy: 0.6632\n",
            "Epoch 10/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3533 - accuracy: 0.8751 - val_loss: 1.3821 - val_accuracy: 0.6494\n",
            "Epoch 11/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2999 - accuracy: 0.8946 - val_loss: 1.3915 - val_accuracy: 0.6370\n",
            "Epoch 12/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2482 - accuracy: 0.9124 - val_loss: 1.5936 - val_accuracy: 0.6422\n",
            "Epoch 13/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2153 - accuracy: 0.9237 - val_loss: 1.6512 - val_accuracy: 0.6464\n",
            "Epoch 14/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1770 - accuracy: 0.9364 - val_loss: 1.8158 - val_accuracy: 0.6522\n",
            "Epoch 15/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1703 - accuracy: 0.9386 - val_loss: 1.9975 - val_accuracy: 0.6422\n",
            "Epoch 16/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1528 - accuracy: 0.9456 - val_loss: 2.0554 - val_accuracy: 0.6414\n",
            "Epoch 17/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1462 - accuracy: 0.9498 - val_loss: 2.1929 - val_accuracy: 0.6468\n",
            "Epoch 18/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1535 - accuracy: 0.9466 - val_loss: 2.2536 - val_accuracy: 0.6430\n",
            "Epoch 19/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1294 - accuracy: 0.9542 - val_loss: 2.4200 - val_accuracy: 0.6322\n",
            "Epoch 20/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1068 - accuracy: 0.9626 - val_loss: 2.4164 - val_accuracy: 0.6472\n",
            "Epoch 21/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1200 - accuracy: 0.9590 - val_loss: 2.5666 - val_accuracy: 0.6314\n",
            "Epoch 22/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0999 - accuracy: 0.9651 - val_loss: 2.5284 - val_accuracy: 0.6352\n",
            "Epoch 23/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1130 - accuracy: 0.9622 - val_loss: 2.7171 - val_accuracy: 0.6332\n",
            "Epoch 24/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1017 - accuracy: 0.9645 - val_loss: 2.7036 - val_accuracy: 0.6458\n",
            "Epoch 25/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 2.7297 - val_accuracy: 0.6394\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3440 - accuracy: 0.9401\n",
            "Test loss: 0.34399425983428955\n",
            "Test accuracy: 0.9401199817657471\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_51 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_34 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_35 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "300/300 [==============================] - 3s 7ms/step - loss: 1.6207 - accuracy: 0.4106 - val_loss: 1.3999 - val_accuracy: 0.4936\n",
            "Epoch 2/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2865 - accuracy: 0.5410 - val_loss: 1.2036 - val_accuracy: 0.5740\n",
            "Epoch 3/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1015 - accuracy: 0.6112 - val_loss: 1.0511 - val_accuracy: 0.6278\n",
            "Epoch 4/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.9824 - accuracy: 0.6529 - val_loss: 0.9859 - val_accuracy: 0.6514\n",
            "Epoch 5/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.8854 - accuracy: 0.6886 - val_loss: 0.9521 - val_accuracy: 0.6722\n",
            "Epoch 6/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.8038 - accuracy: 0.7173 - val_loss: 0.9461 - val_accuracy: 0.6762\n",
            "Epoch 7/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.7326 - accuracy: 0.7422 - val_loss: 0.9624 - val_accuracy: 0.6676\n",
            "Epoch 8/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.6509 - accuracy: 0.7738 - val_loss: 0.9209 - val_accuracy: 0.6992\n",
            "Epoch 9/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5846 - accuracy: 0.7947 - val_loss: 0.9654 - val_accuracy: 0.6906\n",
            "Epoch 10/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5094 - accuracy: 0.8206 - val_loss: 1.0257 - val_accuracy: 0.6862\n",
            "Epoch 11/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.4412 - accuracy: 0.8434 - val_loss: 1.1242 - val_accuracy: 0.6694\n",
            "Epoch 12/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3803 - accuracy: 0.8656 - val_loss: 1.1998 - val_accuracy: 0.6790\n",
            "Epoch 13/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3251 - accuracy: 0.8840 - val_loss: 1.2686 - val_accuracy: 0.6812\n",
            "Epoch 14/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.2892 - accuracy: 0.8962 - val_loss: 1.4122 - val_accuracy: 0.6554\n",
            "Epoch 15/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.2494 - accuracy: 0.9115 - val_loss: 1.5378 - val_accuracy: 0.6460\n",
            "Epoch 16/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.2273 - accuracy: 0.9181 - val_loss: 1.6173 - val_accuracy: 0.6618\n",
            "Epoch 17/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1696 - accuracy: 0.9402 - val_loss: 1.8167 - val_accuracy: 0.6552\n",
            "Epoch 18/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1672 - accuracy: 0.9403 - val_loss: 1.8137 - val_accuracy: 0.6526\n",
            "Epoch 19/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1517 - accuracy: 0.9456 - val_loss: 2.0523 - val_accuracy: 0.6598\n",
            "Epoch 20/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1464 - accuracy: 0.9472 - val_loss: 2.1459 - val_accuracy: 0.6400\n",
            "Epoch 21/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1538 - accuracy: 0.9457 - val_loss: 2.1165 - val_accuracy: 0.6522\n",
            "Epoch 22/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1321 - accuracy: 0.9538 - val_loss: 2.2453 - val_accuracy: 0.6580\n",
            "Epoch 23/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.0960 - accuracy: 0.9665 - val_loss: 2.3332 - val_accuracy: 0.6584\n",
            "Epoch 24/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1305 - accuracy: 0.9542 - val_loss: 2.3362 - val_accuracy: 0.6464\n",
            "Epoch 25/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.1023 - accuracy: 0.9644 - val_loss: 2.4842 - val_accuracy: 0.6496\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3352 - accuracy: 0.9350\n",
            "Test loss: 0.33518290519714355\n",
            "Test accuracy: 0.9350399971008301\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_36 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_37 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "225/225 [==============================] - 3s 10ms/step - loss: 1.6058 - accuracy: 0.4147 - val_loss: 1.2861 - val_accuracy: 0.5496\n",
            "Epoch 2/25\n",
            "225/225 [==============================] - 2s 10ms/step - loss: 1.2198 - accuracy: 0.5655 - val_loss: 1.1316 - val_accuracy: 0.6004\n",
            "Epoch 3/25\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 1.0504 - accuracy: 0.6310 - val_loss: 1.0231 - val_accuracy: 0.6452\n",
            "Epoch 4/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.9120 - accuracy: 0.6825 - val_loss: 0.9531 - val_accuracy: 0.6664\n",
            "Epoch 5/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.8038 - accuracy: 0.7187 - val_loss: 0.9771 - val_accuracy: 0.6680\n",
            "Epoch 6/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.6974 - accuracy: 0.7572 - val_loss: 0.9411 - val_accuracy: 0.6806\n",
            "Epoch 7/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.5896 - accuracy: 0.7942 - val_loss: 0.9914 - val_accuracy: 0.6766\n",
            "Epoch 8/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.4899 - accuracy: 0.8275 - val_loss: 1.0866 - val_accuracy: 0.6680\n",
            "Epoch 9/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.3884 - accuracy: 0.8646 - val_loss: 1.2030 - val_accuracy: 0.6742\n",
            "Epoch 10/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.2984 - accuracy: 0.8943 - val_loss: 1.3041 - val_accuracy: 0.6598\n",
            "Epoch 11/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.2372 - accuracy: 0.9164 - val_loss: 1.4456 - val_accuracy: 0.6696\n",
            "Epoch 12/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1872 - accuracy: 0.9344 - val_loss: 1.6222 - val_accuracy: 0.6536\n",
            "Epoch 13/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1611 - accuracy: 0.9434 - val_loss: 1.7747 - val_accuracy: 0.6650\n",
            "Epoch 14/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1395 - accuracy: 0.9495 - val_loss: 1.9554 - val_accuracy: 0.6470\n",
            "Epoch 15/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1153 - accuracy: 0.9590 - val_loss: 2.1101 - val_accuracy: 0.6432\n",
            "Epoch 16/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1147 - accuracy: 0.9600 - val_loss: 2.0737 - val_accuracy: 0.6542\n",
            "Epoch 17/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1202 - accuracy: 0.9582 - val_loss: 2.2542 - val_accuracy: 0.6500\n",
            "Epoch 18/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0998 - accuracy: 0.9653 - val_loss: 2.2786 - val_accuracy: 0.6536\n",
            "Epoch 19/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0840 - accuracy: 0.9712 - val_loss: 2.4237 - val_accuracy: 0.6604\n",
            "Epoch 20/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0799 - accuracy: 0.9724 - val_loss: 2.5668 - val_accuracy: 0.6444\n",
            "Epoch 21/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 2.6563 - val_accuracy: 0.6456\n",
            "Epoch 22/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0857 - accuracy: 0.9711 - val_loss: 2.5413 - val_accuracy: 0.6524\n",
            "Epoch 23/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0910 - accuracy: 0.9697 - val_loss: 2.7312 - val_accuracy: 0.6440\n",
            "Epoch 24/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0870 - accuracy: 0.9717 - val_loss: 2.7545 - val_accuracy: 0.6478\n",
            "Epoch 25/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.0951 - accuracy: 0.9684 - val_loss: 2.6144 - val_accuracy: 0.6454\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3105 - accuracy: 0.9480\n",
            "Test loss: 0.3104947805404663\n",
            "Test accuracy: 0.9479600191116333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the accuracy of different batch size\n",
        "a = range(len(batchsize_list))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(a, Accuracy2, \"*\")\n",
        "#plt.scatter(a, Accuracy)\n",
        "\n",
        "ax.set_xticks(a)\n",
        "ax.set_xticklabels(batchsize_list)\n",
        "\n",
        "plt.xlabel('batch size')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('The effect of learning rate')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "SkztVv2zXsy5",
        "outputId": "ff34c816-0323-49ef-964e-e7c656521ce0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Accuracy2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrgBxAPZCvb",
        "outputId": "ce9497f9-0971-4150-9cdf-fa8fa00c49fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9050800204277039, 0.9305599927902222, 0.9078199863433838, 0.9232800006866455, 0.9289799928665161, 0.9401199817657471, 0.9350399971008301, 0.9479600191116333]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best performance model"
      ],
      "metadata": {
        "id": "v8gfUsSIYhvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y8FYjd-e_xa",
        "outputId": "82c5ff16-34b6-4793-9b15-c98f9c7d2f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_57 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_38 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_39 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a LeNet Convolutional Neural Network\n",
        "\n",
        "cnn_model = keras.Sequential()\n",
        "#layer 1-2\n",
        "cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#layer 3-4\n",
        "cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#layer 5\n",
        "cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "cnn_model.add(keras.layers.Flatten())\n",
        "#layer 6\n",
        "cnn_model.add(keras.layers.Dense(84))\n",
        "cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "# layer 7 output layer\n",
        "cnn_model.add(keras.layers.Dense(n_class))\n",
        "cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "cnn_model.build(input_shape=(1,32,32,3))\n",
        "# print summary of the model\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORf457XM0t97",
        "outputId": "f8725d0c-59c1-433a-80d5-cf07b25aff6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.6806 - accuracy: 0.3875 - val_loss: 1.4359 - val_accuracy: 0.4910\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3325 - accuracy: 0.5210 - val_loss: 1.2334 - val_accuracy: 0.5716\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.1717 - accuracy: 0.5843 - val_loss: 1.1079 - val_accuracy: 0.6162\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0597 - accuracy: 0.6292 - val_loss: 1.0403 - val_accuracy: 0.6404\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9759 - accuracy: 0.6564 - val_loss: 1.0066 - val_accuracy: 0.6584\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8977 - accuracy: 0.6864 - val_loss: 0.9747 - val_accuracy: 0.6762\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8266 - accuracy: 0.7125 - val_loss: 0.9657 - val_accuracy: 0.6708\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7651 - accuracy: 0.7327 - val_loss: 0.9299 - val_accuracy: 0.6832\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7071 - accuracy: 0.7549 - val_loss: 0.9213 - val_accuracy: 0.6914\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6536 - accuracy: 0.7711 - val_loss: 0.9455 - val_accuracy: 0.6924\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5934 - accuracy: 0.7926 - val_loss: 0.9468 - val_accuracy: 0.6880\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5444 - accuracy: 0.8088 - val_loss: 0.9995 - val_accuracy: 0.6926\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4935 - accuracy: 0.8269 - val_loss: 1.0039 - val_accuracy: 0.6948\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.4385 - accuracy: 0.8476 - val_loss: 1.1179 - val_accuracy: 0.6742\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.3798 - accuracy: 0.8674 - val_loss: 1.1132 - val_accuracy: 0.6794\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3381 - accuracy: 0.8826 - val_loss: 1.1505 - val_accuracy: 0.6742\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3006 - accuracy: 0.8961 - val_loss: 1.2028 - val_accuracy: 0.6946\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2475 - accuracy: 0.9141 - val_loss: 1.3678 - val_accuracy: 0.6788\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2198 - accuracy: 0.9232 - val_loss: 1.3581 - val_accuracy: 0.6938\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1864 - accuracy: 0.9350 - val_loss: 1.5075 - val_accuracy: 0.6816\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1749 - accuracy: 0.9388 - val_loss: 1.6338 - val_accuracy: 0.6622\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1528 - accuracy: 0.9477 - val_loss: 1.7775 - val_accuracy: 0.6762\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1353 - accuracy: 0.9533 - val_loss: 1.8098 - val_accuracy: 0.6716\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1151 - accuracy: 0.9606 - val_loss: 1.8920 - val_accuracy: 0.6780\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1161 - accuracy: 0.9594 - val_loss: 1.9380 - val_accuracy: 0.6878\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2616 - accuracy: 0.9476\n",
            "Test loss: 0.2616298496723175\n",
            "Test accuracy: 0.9476400017738342\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "\n",
        "#define the optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# compile the model\n",
        "cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = cnn_model.evaluate(image_train, class_train)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equivalent feedforwad network"
      ],
      "metadata": {
        "id": "I1EQyh8SYnvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a equivalent feed forward network of the LeNet Convolutional Neural Network\n",
        "\n",
        "ff_model = keras.Sequential()\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "ff_model.add(keras.layers.Flatten())\n",
        "\n",
        "#layer 1-2\n",
        "ff_model.add(keras.layers.Dense(6))\n",
        "#ff_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "#layer 3-4\n",
        "ff_model.add(keras.layers.Dense(16))\n",
        "#ff_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "#layer 5\n",
        "ff_model.add(keras.layers.Dense(120))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "\n",
        "#layer 6\n",
        "ff_model.add(keras.layers.Dense(84))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "# layer 7 output layer\n",
        "ff_model.add(keras.layers.Dense(n_class))\n",
        "ff_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "ff_model.build(input_shape=(1,32,32,3))\n",
        "# print summary of the model\n",
        "ff_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6LOjZQuHHrl",
        "outputId": "c328cfaa-7f0c-4245-ffbb-3d17c8df183d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (1, 3072)                 0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (1, 6)                    18438     \n",
            "                                                                 \n",
            " activation_38 (Activation)  (1, 6)                    0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (1, 16)                   112       \n",
            "                                                                 \n",
            " activation_39 (Activation)  (1, 16)                   0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (1, 120)                  2040      \n",
            "                                                                 \n",
            " activation_40 (Activation)  (1, 120)                  0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (1, 84)                   10164     \n",
            "                                                                 \n",
            " activation_41 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_42 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,604\n",
            "Trainable params: 31,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "\n",
        "#define the optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "# compile the model\n",
        "ff_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "ff_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = ff_model.evaluate(image_train, class_train)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhiNzXSSIDtH",
        "outputId": "e4f8f42b-7305-4bf6-9938-4a54d7ef21c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0655 - accuracy: 0.2138 - val_loss: 2.0190 - val_accuracy: 0.2390\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9475 - accuracy: 0.2626 - val_loss: 1.9502 - val_accuracy: 0.2628\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9305 - accuracy: 0.2693 - val_loss: 1.9204 - val_accuracy: 0.2658\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9194 - accuracy: 0.2733 - val_loss: 1.9537 - val_accuracy: 0.2564\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9140 - accuracy: 0.2731 - val_loss: 1.9199 - val_accuracy: 0.2702\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9107 - accuracy: 0.2769 - val_loss: 1.9159 - val_accuracy: 0.2750\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9052 - accuracy: 0.2749 - val_loss: 1.9108 - val_accuracy: 0.2812\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9031 - accuracy: 0.2783 - val_loss: 1.9128 - val_accuracy: 0.2708\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9005 - accuracy: 0.2813 - val_loss: 1.9116 - val_accuracy: 0.2772\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8988 - accuracy: 0.2807 - val_loss: 1.9167 - val_accuracy: 0.2686\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8957 - accuracy: 0.2832 - val_loss: 1.9064 - val_accuracy: 0.2788\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8970 - accuracy: 0.2836 - val_loss: 1.9135 - val_accuracy: 0.2716\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8941 - accuracy: 0.2823 - val_loss: 1.9172 - val_accuracy: 0.2726\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8922 - accuracy: 0.2845 - val_loss: 1.9053 - val_accuracy: 0.2858\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8896 - accuracy: 0.2855 - val_loss: 1.9122 - val_accuracy: 0.2712\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8897 - accuracy: 0.2855 - val_loss: 1.9087 - val_accuracy: 0.2830\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8898 - accuracy: 0.2871 - val_loss: 1.9118 - val_accuracy: 0.2770\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8879 - accuracy: 0.2875 - val_loss: 1.9478 - val_accuracy: 0.2702\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8869 - accuracy: 0.2862 - val_loss: 1.9001 - val_accuracy: 0.2844\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8869 - accuracy: 0.2890 - val_loss: 1.9136 - val_accuracy: 0.2788\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8852 - accuracy: 0.2890 - val_loss: 1.9071 - val_accuracy: 0.2826\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8834 - accuracy: 0.2889 - val_loss: 1.9000 - val_accuracy: 0.2858\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8828 - accuracy: 0.2898 - val_loss: 1.9008 - val_accuracy: 0.2818\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8832 - accuracy: 0.2928 - val_loss: 1.9043 - val_accuracy: 0.2876\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8820 - accuracy: 0.2897 - val_loss: 1.9099 - val_accuracy: 0.2782\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8845 - accuracy: 0.2880\n",
            "Test loss: 1.8844664096832275\n",
            "Test accuracy: 0.2880200147628784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUpDBTWpfAEK"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z86zoajn3mZg"
      },
      "source": [
        "1. The dimensions of the input is (6, 6, 1), the kernel's size is (3, 3, 1).  There are 10 parameters in the kernel f.\n",
        "\n",
        "2. The output activation map when you apply the convolutional operation using the filter f on the input X without padding is: \n",
        "\n",
        "[[ 16.   9.  -4. -18.]\n",
        " [ 17.  -5. -10. -12.]\n",
        " [ 11.  -9. -17.   2.]\n",
        " [  9.  -1. -15.  16.]]\n",
        "\n",
        "3. the output when you apply a max-pooling operation on the output from the activation map with a pooling filter size of 2 and stride of 2 is:\n",
        "\n",
        "[[17. -4.]\n",
        " [11. 16.]]\n",
        "\n",
        "A pooling filter size of 2 and stride of 1 is:\n",
        "\n",
        "[[17.  9. -4.]\n",
        " [17. -5.  2.]\n",
        " [11. -1. 16.]]\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFJmn6qwBX2y"
      },
      "outputs": [],
      "source": [
        "# function to convlutional\n",
        "# s is stride\n",
        "def conv(input, filter, s = 1):\n",
        "\n",
        "  H = input.shape[0]\n",
        "  F = filter.shape[0]\n",
        "\n",
        "  out_h = H-F+1\n",
        "  acti_map = np.zeros((out_h,out_h))\n",
        "\n",
        "  for j in range(out_h):\n",
        "\n",
        "    for i in range(out_h):\n",
        "\n",
        "      sub_input = input[j:j+F,i:i+F]\n",
        "\n",
        "      acti_map[j, i] = np.sum(sub_input*filter)\n",
        "\n",
        "  return acti_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMsnASbH5VP2"
      },
      "outputs": [],
      "source": [
        "# function to pool\n",
        "# s is stride, f is filter\n",
        "def max_pooling(arr, f = 2, s = 2):\n",
        "\n",
        "  h = arr.shape[0]\n",
        "\n",
        "  out_h = (h-f)//s+1\n",
        "  output = np.zeros((out_h,out_h))\n",
        "\n",
        "  for j in range(out_h):\n",
        "    starty = j*s\n",
        "    for i in range(out_h):\n",
        "\n",
        "      startx = i*s\n",
        "\n",
        "      sub_input = arr[starty:starty+f,startx:startx+f]\n",
        "      #print(sub_input)\n",
        "\n",
        "      output[j, i] = np.max(sub_input)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inout\n",
        "arr_1d = np.array([7,5,0,0,3,2,\n",
        "              6,4,5,1,4,8,\n",
        "              9,0,2,2,5,4,\n",
        "              6,3,4,7,9,8,\n",
        "              5,7,5,6,9,0,\n",
        "              7,9,0,8,2,3])\n",
        "filt = np.array([1,0,-1,\n",
        "             2, 0, -2,\n",
        "             1, 0, -1])\n",
        "\n",
        "arr_2d = arr_1d.reshape(6,6)\n",
        "filt = filt.reshape(3, 3)\n",
        "\n",
        "# call function to conv\n",
        "activation_map = conv(arr_2d, filt)\n",
        "# call function to pool\n",
        "pool_map = max_pooling(activation_map, f = 2, s = 2)\n"
      ],
      "metadata": {
        "id": "5lC2hXX9DkcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(activation_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M63_wjD0D4CB",
        "outputId": "7df0106d-4858-41a1-8256-c38b7b5be516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 16.   9.  -4. -18.]\n",
            " [ 17.  -5. -10. -12.]\n",
            " [ 11.  -9. -17.   2.]\n",
            " [  9.  -1. -15.  16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pool_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XheigLe2D60C",
        "outputId": "82c38740-e43f-45b0-8302-1706cad7c1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17. -4.]\n",
            " [11. 16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_pooling(activation_map, f = 2, s = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7WuuyUjG9wX",
        "outputId": "e6846d9c-5d83-4fa9-99ba-a30ef84b3d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.  9. -4.]\n",
            " [17. -5.  2.]\n",
            " [11. -1. 16.]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}