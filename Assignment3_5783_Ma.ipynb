{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDLECHCQebBb"
      },
      "outputs": [],
      "source": [
        "#  these code refered from keras document https://keras.io/examples/vision/mnist_convnet/\n",
        "\n",
        "# import library\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "import tensorboard\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wL_g1sruIoj"
      },
      "source": [
        "#Question 1 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYxsWL2jw3Lj"
      },
      "source": [
        "First I tested the effect of batch size. I use epoch = 5, default Adam optimizer. I tested the accuracy when batchsize is 1, 5, 10, 32, 64, 128,256 respectively. When batchsize = 1, the accuracy is 0.79. When batchsize = 5, the accuracy is 0.83. When batchsize = 5, the accuracy is 0.98. The accuracy is 0.99 when batchsize is 32,64,128. \n",
        "\n",
        "Then I tested the effect of learning rate. I used epoch = 5, batch size is 128, default Adam optimizer.  I tested the accuracy when learning rate is 0.01, 0.005, 0.001, 0.0005, 0.0001 respectively. When learning rate is 0.01,  test accuracy is 0.10. When learning rate is 0.005,  test accuracy is 0.11. When learning rate is 0.001,  test accuracy is  0.984. When learning rate is 0.0005 and 0.0001,  test accuracy is 0.99. \n",
        "\n",
        "Then I tested the effect of the optimizer. I used epoch = 5, batch size is 128,the default Adam, SGD, and RMSprop optimizer. All three optimizers have the test accuracy of 0.99. \n",
        "\n",
        "The final accuracy of the regular CNN is 0.99, inverted CNN, and hour-glass shaped CNN are all 0.987. Regular CNN is slightly better than the other two."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCZKBsgAjQ2E",
        "outputId": "5c6446f6-2d9e-464e-a45b-13667c2a1263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Load the MNIST dataset\n",
        "\n",
        "# number of classes\n",
        "n_class = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(image_train, class_train),(image_test, class_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "image_train = image_train.astype(\"float32\") / 255\n",
        "image_test = image_test.astype(\"float32\") / 255\n",
        "\n",
        "#add an additional dimension to represent the single-channel\n",
        "x_train = image_train.reshape(-1, 28, 28, 1) \n",
        "x_test = image_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(class_train, n_class)\n",
        "y_test = keras.utils.to_categorical(class_test, n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs69yf4nk2ij"
      },
      "source": [
        "1.1. A regular CNN where the number of filters in each layer increases as the depth of the network grows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOHBJ4ZQrzLf",
        "outputId": "1b007e06-41c1-436f-a694-759cefc1f7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 28, 28, 6)            60        \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 28, 28, 10)           550       \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 28, 28, 16)           1456      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (1, 14, 14, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (1, 14, 14, 24)           3480      \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 14, 14, 32)           6944      \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 14, 14, 48)           13872     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (1, 7, 7, 48)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (1, 7, 7, 64)             27712     \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 7, 7, 96)             55392     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (1, 3, 3, 96)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 3, 3, 128)            110720    \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (1, 3, 3, 256)            295168    \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (1, 1, 1, 256)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 256)                  0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 256)                  65792     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 256)                  0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   2570      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 583,716\n",
            "Trainable params: 583,716\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(10, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(24, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(48, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(96, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn.add(keras.layers.Conv2D(128, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.Conv2D(256, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn.add(keras.layers.Flatten())\n",
        "regular_cnn.add(keras.layers.Dense(256))\n",
        "regular_cnn.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn.add(keras.layers.Dense(n_class))\n",
        "regular_cnn.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8w6ySAOLl9W5",
        "outputId": "0c6cb364-1d2b-4a2e-839b-520c71b3e232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5400/5400 [==============================] - 42s 6ms/step - loss: 0.1995 - accuracy: 0.9380 - val_loss: 0.0689 - val_accuracy: 0.9805\n",
            "Epoch 2/5\n",
            "5400/5400 [==============================] - 33s 6ms/step - loss: 0.0761 - accuracy: 0.9789 - val_loss: 0.0442 - val_accuracy: 0.9882\n",
            "Epoch 3/5\n",
            "5400/5400 [==============================] - 32s 6ms/step - loss: 0.0629 - accuracy: 0.9827 - val_loss: 0.0392 - val_accuracy: 0.9897\n",
            "Epoch 4/5\n",
            "5400/5400 [==============================] - 32s 6ms/step - loss: 0.0560 - accuracy: 0.9854 - val_loss: 0.0437 - val_accuracy: 0.9895\n",
            "Epoch 5/5\n",
            "5400/5400 [==============================] - 33s 6ms/step - loss: 0.0529 - accuracy: 0.9860 - val_loss: 0.0368 - val_accuracy: 0.9905\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0347 - accuracy: 0.9903\n",
            "Test loss: 0.03468652814626694\n",
            "Test accuracy: 0.9902999997138977\n"
          ]
        }
      ],
      "source": [
        "# test the effect of batch size to test accuracy\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 5\n",
        "\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # test the effect of learning rate to test accuracy\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "opt1 = keras.optimizers.Adam(learning_rate=0.005)\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer=opt1, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnZvMVefcZCi",
        "outputId": "a703a5e9-2918-4262-dd0a-649cf06c71b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 5s 10ms/step - loss: 0.5600 - accuracy: 0.8022 - val_loss: 0.0985 - val_accuracy: 0.9707\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.1055 - accuracy: 0.9683 - val_loss: 0.0647 - val_accuracy: 0.9803\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0795 - accuracy: 0.9765 - val_loss: 0.0543 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0686 - accuracy: 0.9802 - val_loss: 0.0556 - val_accuracy: 0.9850\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0623 - accuracy: 0.9816 - val_loss: 0.0516 - val_accuracy: 0.9843\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9863\n",
            "Test loss: 0.04517043009400368\n",
            "Test accuracy: 0.986299991607666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e24Eb8CO9y5",
        "outputId": "abffad48-3f48-4bcf-803a-fdc7c99ae334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 6s 11ms/step - loss: 0.2797 - accuracy: 0.9092 - val_loss: 0.0558 - val_accuracy: 0.9832\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 4s 10ms/step - loss: 0.0579 - accuracy: 0.9814 - val_loss: 0.0393 - val_accuracy: 0.9878\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 5s 13ms/step - loss: 0.0405 - accuracy: 0.9877 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 4s 11ms/step - loss: 0.0308 - accuracy: 0.9904 - val_loss: 0.0334 - val_accuracy: 0.9907\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 5s 12ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0271 - val_accuracy: 0.9922\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9919\n",
            "Test loss: 0.026087500154972076\n",
            "Test accuracy: 0.9919000267982483\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # test the effect of optimizer to test accuracy\n",
        "\n",
        "# opt1 = keras.optimizers.Adam(learning_rate=0.001)\n",
        "# opt2 = keras.optimizers.SGD(learning_rate=0.001)\n",
        "# opt3 = keras.optimizers.RMSprop( learning_rate=0.001,   rho=0.9,   momentum=0.0)\n",
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sPSrgreupmi"
      },
      "source": [
        "1.2. An inverted CNN where the number of filters in each layer decreases as the depth of the network grows "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IG76hoQupGf",
        "outputId": "84bb317c-541d-4f31-f1bd-421131bd1584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (1, 28, 28, 256)          2560      \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (1, 28, 28, 128)          295040    \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (1, 28, 28, 96)           110688    \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (1, 14, 14, 96)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (1, 14, 14, 64)           55360     \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (1, 14, 14, 48)           27696     \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (1, 14, 14, 32)           13856     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (1, 7, 7, 32)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (1, 7, 7, 24)             6936      \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (1, 7, 7, 16)             3472      \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (1, 3, 3, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (1, 3, 3, 10)             1450      \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (1, 3, 3, 6)              546       \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (1, 1, 1, 6)             0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 6)                    0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (1, 1024)                 7168      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (1, 10)                   10250     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 535,022\n",
            "Trainable params: 535,022\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn2 = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn2.add(keras.layers.Conv2D(256, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(128, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(96, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn2.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(48, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn2.add(keras.layers.Conv2D(24, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "regular_cnn2.add(keras.layers.Conv2D(10, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(768, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(1024, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn2.add(keras.layers.Flatten())\n",
        "regular_cnn2.add(keras.layers.Dense(1024))\n",
        "regular_cnn2.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn2.add(keras.layers.Dense(n_class))\n",
        "regular_cnn2.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn2.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn2.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn2.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyMUstp0DTew",
        "outputId": "689f17de-32ec-4334-d3a9-4de9fa15a264"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 24s 52ms/step - loss: 0.3497 - accuracy: 0.8839 - val_loss: 0.0816 - val_accuracy: 0.9748\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 21s 49ms/step - loss: 0.0858 - accuracy: 0.9747 - val_loss: 0.0744 - val_accuracy: 0.9792\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0630 - accuracy: 0.9815 - val_loss: 0.0445 - val_accuracy: 0.9875\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.0414 - val_accuracy: 0.9875\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 20s 48ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 0.0326 - val_accuracy: 0.9913\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0389 - accuracy: 0.9879\n",
            "Test loss: 0.03893260285258293\n",
            "Test accuracy: 0.9879000186920166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.3. An hour-glass shaped CNN where the number of filters will increase till the Lth layer and reduce afterwards"
      ],
      "metadata": {
        "id": "ZEkMWh9_415M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a 10-layer regular CNN model\n",
        "\n",
        "regular_cnn3 = keras.Sequential()\n",
        "#regular_cnn = keras.models.Sequential()\n",
        "regular_cnn3.add(keras.layers.Conv2D(6, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(16, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn3.add(keras.layers.Conv2D(64, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(96, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(128, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "regular_cnn3.add(keras.layers.Conv2D(96, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(64, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "regular_cnn3.add(keras.layers.Conv2D(32, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.Conv2D(16, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(768, kernel_size=(3, 3), padding='same',activation=\"relu\"))\n",
        "#regular_cnn.add(keras.layers.Conv2D(1024, kernel_size=(3, 3),padding='same', activation=\"relu\"))\n",
        "regular_cnn3.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "regular_cnn3.add(keras.layers.Flatten())\n",
        "regular_cnn3.add(keras.layers.Dense(1024))\n",
        "regular_cnn3.add(keras.layers.Activation('relu'))\n",
        "#regular_cnn.add(keras.layers.Dense(256))\n",
        "#regular_cnn.add(keras.layers.Activation('relu'))\n",
        "# output layer\n",
        "regular_cnn3.add(keras.layers.Dense(n_class))\n",
        "regular_cnn3.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "regular_cnn3.build(input_shape=(1,28,28,1))\n",
        "# print summary of the model\n",
        "regular_cnn3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chBNuPSX40cu",
        "outputId": "8c8ed846-56cd-448c-cd2a-5e746736c8a5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (1, 28, 28, 6)            60        \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (1, 28, 28, 16)           880       \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (1, 28, 28, 32)           4640      \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (1, 14, 14, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (1, 14, 14, 64)           18496     \n",
            "                                                                 \n",
            " conv2d_54 (Conv2D)          (1, 14, 14, 96)           55392     \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (1, 14, 14, 128)          110720    \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (1, 7, 7, 128)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (1, 7, 7, 96)             110688    \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (1, 7, 7, 64)             55360     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (1, 3, 3, 64)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (1, 3, 3, 32)             18464     \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (1, 3, 3, 16)             4624      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (1, 1, 1, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 16)                   0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (1, 1024)                 17408     \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 1024)                 0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (1, 10)                   10250     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 406,982\n",
            "Trainable params: 406,982\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "# compile the model\n",
        "regular_cnn3.compile(loss=\"categorical_crossentropy\", optimizer='Adam', metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "regular_cnn3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = regular_cnn3.evaluate(x_test, y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "outputId": "7b240a22-3dc5-4453-c843-25c8a288d426",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBDvoBOQEMRY"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "422/422 [==============================] - 9s 17ms/step - loss: 0.4029 - accuracy: 0.8636 - val_loss: 0.1007 - val_accuracy: 0.9683\n",
            "Epoch 2/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.1011 - accuracy: 0.9685 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
            "Epoch 3/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0642 - accuracy: 0.9801 - val_loss: 0.0505 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0483 - accuracy: 0.9854 - val_loss: 0.0478 - val_accuracy: 0.9858\n",
            "Epoch 5/5\n",
            "422/422 [==============================] - 7s 16ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 0.0441 - val_accuracy: 0.9883\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9875\n",
            "Test loss: 0.04437745735049248\n",
            "Test accuracy: 0.987500011920929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngL3xaFvfvev"
      },
      "source": [
        "# Question 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78E2KxfCe2Hf"
      },
      "source": [
        "1. What is the effect of learning rate on the training process? Which performed best?\n",
        "I tried 11 different learning rate to study its effect to the training process. when learning rate is 0.00075 and 0.001 have the best performance. When learning rate get bigger, the performance becomes worse. when learning rate greater than 0.01, the best accuracy is 0.1. The learning rate and test accuracy are [0.0005, 0.00075, 0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.025, 0.05] and [0.914900004863739, 0.9542199969291687, 0.9473400115966797, 0.936680018901825, 0.929099977016449, 0.9061999917030334, 0.8217999935150146, 0.10000000149011612, 0.6461399793624878, 0.10000000149011612, 0.10000000149011612] respectively.\n",
        "2. I tried 8 different batch size to study its effect to the training process. when learning rate is 120 have the best performance. The batch size and test accuracy are [20, 40, 60, 80,100,120,150,200] and [0.9039199948310852, 0.9319599866867065, 0.9172000288963318, 0.9109600186347961, 0.9246199727058411, 0.9423999786376953, 0.9279400110244751, 0.9297000169754028] respectively.\n",
        "3. I tried different hyperparamters and figure out the best performance happens when learning rate = 0.001 and batchsize is 128. The test accuracy is 0.95.\n",
        "4. a. The performance of FF model is much worse than CNN model. the test accuracy is 0.288. \n",
        "b. FF has 31,604 parameters, the Lenet has 697046 parameters. LeNet has more parameters than FF model, but its worth it. The performance of LeNet is much better than FF model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read training and testing data"
      ],
      "metadata": {
        "id": "yatFZqGaYKWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDRFVftrzs6E",
        "outputId": "03698668-06e3-458f-9a30-22361af57955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n",
            "image_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "50000 test samples\n"
          ]
        }
      ],
      "source": [
        "# number of classes\n",
        "n_class = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(image_train, class_train),(image_test, class_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "image_train = image_train.astype(\"float32\") / 255\n",
        "image_test = image_test.astype(\"float32\") / 255\n",
        "\n",
        "#add an additional dimension to represent the single-channel\n",
        "image_train = image_train.reshape(-1, 32, 32, 3) \n",
        "image_test = image_test.reshape(-1, 32, 32, 3)\n",
        "\n",
        "print(\"image_train shape:\", image_train.shape)\n",
        "print(image_train.shape[0], \"train samples\")\n",
        "print(image_train.shape[0], \"test samples\")\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "class_train = keras.utils.to_categorical(class_train, n_class)\n",
        "class_test = keras.utils.to_categorical(class_test, n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The effect of learning rate"
      ],
      "metadata": {
        "id": "pAb9xBLmYQvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_list = [0.0005, 0.00075, 0.001, 0.002, 0.003, 0.004, 0.005, 0.0075, 0.01, 0.025, 0.05]\n",
        "Accuracy = []\n",
        "for lr in lr_list:\n",
        "  # Build a LeNet Convolutional Neural Network\n",
        "\n",
        "  cnn_model = keras.Sequential()\n",
        "  #layer 1-2\n",
        "  cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 3-4\n",
        "  cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 5\n",
        "  cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "  #flatten 2d data to 1d\n",
        "  cnn_model.add(keras.layers.Flatten())\n",
        "  #layer 6\n",
        "  cnn_model.add(keras.layers.Dense(84))\n",
        "  cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "  # layer 7 output layer\n",
        "  cnn_model.add(keras.layers.Dense(n_class))\n",
        "  cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model.build(input_shape=(1,32,32,3))\n",
        "  # print summary of the model\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # train the model\n",
        "  epochs = 25\n",
        "  batch_size = 128\n",
        "\n",
        "  #define the optimizer\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  # compile the model\n",
        "  cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  # train the model\n",
        "  cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  # Evaluate\n",
        "  score = cnn_model.evaluate(image_train, class_train)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "  Accuracy.append(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Swq-IBJ866G",
        "outputId": "8f01b98c-8c57-46eb-cca1-17a70c4354e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (1, 16, 16, 6)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation (Activation)     (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 11s 8ms/step - loss: 1.7110 - accuracy: 0.3829 - val_loss: 1.4787 - val_accuracy: 0.4700\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 3s 10ms/step - loss: 1.4060 - accuracy: 0.4991 - val_loss: 1.3441 - val_accuracy: 0.5178\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.2839 - accuracy: 0.5472 - val_loss: 1.2208 - val_accuracy: 0.5674\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.1819 - accuracy: 0.5822 - val_loss: 1.1468 - val_accuracy: 0.5994\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0992 - accuracy: 0.6144 - val_loss: 1.1310 - val_accuracy: 0.6034\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0311 - accuracy: 0.6384 - val_loss: 1.0799 - val_accuracy: 0.6286\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9767 - accuracy: 0.6596 - val_loss: 1.0203 - val_accuracy: 0.6478\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9193 - accuracy: 0.6794 - val_loss: 1.0058 - val_accuracy: 0.6492\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8685 - accuracy: 0.6971 - val_loss: 0.9955 - val_accuracy: 0.6534\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8216 - accuracy: 0.7143 - val_loss: 0.9799 - val_accuracy: 0.6634\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7793 - accuracy: 0.7296 - val_loss: 0.9456 - val_accuracy: 0.6858\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7229 - accuracy: 0.7480 - val_loss: 0.9631 - val_accuracy: 0.6746\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6799 - accuracy: 0.7628 - val_loss: 0.9775 - val_accuracy: 0.6730\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6438 - accuracy: 0.7775 - val_loss: 0.9495 - val_accuracy: 0.6838\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5965 - accuracy: 0.7934 - val_loss: 0.9636 - val_accuracy: 0.6842\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5535 - accuracy: 0.8102 - val_loss: 0.9951 - val_accuracy: 0.6810\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5096 - accuracy: 0.8247 - val_loss: 1.0082 - val_accuracy: 0.6850\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4637 - accuracy: 0.8411 - val_loss: 1.0344 - val_accuracy: 0.6818\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4269 - accuracy: 0.8550 - val_loss: 1.0897 - val_accuracy: 0.6778\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3841 - accuracy: 0.8693 - val_loss: 1.1125 - val_accuracy: 0.6772\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3466 - accuracy: 0.8830 - val_loss: 1.1361 - val_accuracy: 0.6796\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3128 - accuracy: 0.8939 - val_loss: 1.1960 - val_accuracy: 0.6716\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2746 - accuracy: 0.9074 - val_loss: 1.2350 - val_accuracy: 0.6742\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2363 - accuracy: 0.9212 - val_loss: 1.3131 - val_accuracy: 0.6800\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2135 - accuracy: 0.9301 - val_loss: 1.4297 - val_accuracy: 0.6672\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3017 - accuracy: 0.9149\n",
            "Test loss: 0.30172139406204224\n",
            "Test accuracy: 0.914900004863739\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 4s 9ms/step - loss: 1.6987 - accuracy: 0.3797 - val_loss: 1.4898 - val_accuracy: 0.4562\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3968 - accuracy: 0.4962 - val_loss: 1.2566 - val_accuracy: 0.5518\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2183 - accuracy: 0.5674 - val_loss: 1.1273 - val_accuracy: 0.5970\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0848 - accuracy: 0.6164 - val_loss: 1.0449 - val_accuracy: 0.6350\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9976 - accuracy: 0.6491 - val_loss: 1.0259 - val_accuracy: 0.6474\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9142 - accuracy: 0.6786 - val_loss: 1.0162 - val_accuracy: 0.6370\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8454 - accuracy: 0.7026 - val_loss: 0.9405 - val_accuracy: 0.6750\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7743 - accuracy: 0.7305 - val_loss: 0.9230 - val_accuracy: 0.6792\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7142 - accuracy: 0.7528 - val_loss: 0.9140 - val_accuracy: 0.6882\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6499 - accuracy: 0.7748 - val_loss: 0.9108 - val_accuracy: 0.6956\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5933 - accuracy: 0.7944 - val_loss: 0.9430 - val_accuracy: 0.6902\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5300 - accuracy: 0.8160 - val_loss: 0.9228 - val_accuracy: 0.6934\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4704 - accuracy: 0.8372 - val_loss: 0.9899 - val_accuracy: 0.6930\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4186 - accuracy: 0.8556 - val_loss: 1.0091 - val_accuracy: 0.6970\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3623 - accuracy: 0.8762 - val_loss: 1.0568 - val_accuracy: 0.6966\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3129 - accuracy: 0.8941 - val_loss: 1.1866 - val_accuracy: 0.6866\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2717 - accuracy: 0.9080 - val_loss: 1.1804 - val_accuracy: 0.6868\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2272 - accuracy: 0.9244 - val_loss: 1.2602 - val_accuracy: 0.6852\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1872 - accuracy: 0.9372 - val_loss: 1.3513 - val_accuracy: 0.6832\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1600 - accuracy: 0.9474 - val_loss: 1.4481 - val_accuracy: 0.6800\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1371 - accuracy: 0.9556 - val_loss: 1.5188 - val_accuracy: 0.6734\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1169 - accuracy: 0.9619 - val_loss: 1.7318 - val_accuracy: 0.6712\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1025 - accuracy: 0.9670 - val_loss: 1.6919 - val_accuracy: 0.6804\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 1.8293 - val_accuracy: 0.6736\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0878 - accuracy: 0.9708 - val_loss: 1.8562 - val_accuracy: 0.6830\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2374 - accuracy: 0.9542\n",
            "Test loss: 0.23739859461784363\n",
            "Test accuracy: 0.9542199969291687\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.6489 - accuracy: 0.4066 - val_loss: 1.3560 - val_accuracy: 0.5238\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2977 - accuracy: 0.5384 - val_loss: 1.3347 - val_accuracy: 0.5258\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1361 - accuracy: 0.5994 - val_loss: 1.1434 - val_accuracy: 0.5912\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0173 - accuracy: 0.6427 - val_loss: 1.0480 - val_accuracy: 0.6334\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9256 - accuracy: 0.6771 - val_loss: 1.0191 - val_accuracy: 0.6460\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8355 - accuracy: 0.7046 - val_loss: 0.9895 - val_accuracy: 0.6664\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7566 - accuracy: 0.7334 - val_loss: 0.9934 - val_accuracy: 0.6598\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6699 - accuracy: 0.7666 - val_loss: 1.0196 - val_accuracy: 0.6660\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5905 - accuracy: 0.7934 - val_loss: 1.0439 - val_accuracy: 0.6580\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5130 - accuracy: 0.8236 - val_loss: 1.0963 - val_accuracy: 0.6552\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4390 - accuracy: 0.8456 - val_loss: 1.1754 - val_accuracy: 0.6614\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3654 - accuracy: 0.8724 - val_loss: 1.2177 - val_accuracy: 0.6638\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3052 - accuracy: 0.8954 - val_loss: 1.3656 - val_accuracy: 0.6610\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2486 - accuracy: 0.9141 - val_loss: 1.4222 - val_accuracy: 0.6632\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2054 - accuracy: 0.9301 - val_loss: 1.6319 - val_accuracy: 0.6406\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1667 - accuracy: 0.9445 - val_loss: 1.7466 - val_accuracy: 0.6474\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1449 - accuracy: 0.9507 - val_loss: 1.8129 - val_accuracy: 0.6506\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1325 - accuracy: 0.9536 - val_loss: 2.0267 - val_accuracy: 0.6416\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1124 - accuracy: 0.9612 - val_loss: 2.0900 - val_accuracy: 0.6486\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1076 - accuracy: 0.9620 - val_loss: 2.1183 - val_accuracy: 0.6496\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1041 - accuracy: 0.9645 - val_loss: 2.3424 - val_accuracy: 0.6420\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0894 - accuracy: 0.9691 - val_loss: 2.3219 - val_accuracy: 0.6418\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0787 - accuracy: 0.9732 - val_loss: 2.5660 - val_accuracy: 0.6406\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0838 - accuracy: 0.9699 - val_loss: 2.6087 - val_accuracy: 0.6328\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0932 - accuracy: 0.9675 - val_loss: 2.4631 - val_accuracy: 0.6444\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2997 - accuracy: 0.9473\n",
            "Test loss: 0.2997097671031952\n",
            "Test accuracy: 0.9473400115966797\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_6 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.6946 - accuracy: 0.3817 - val_loss: 1.3695 - val_accuracy: 0.5062\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2698 - accuracy: 0.5454 - val_loss: 1.2012 - val_accuracy: 0.5688\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1071 - accuracy: 0.6057 - val_loss: 1.0734 - val_accuracy: 0.6176\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9931 - accuracy: 0.6515 - val_loss: 1.0113 - val_accuracy: 0.6386\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.8943 - accuracy: 0.6850 - val_loss: 0.9796 - val_accuracy: 0.6454\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.8054 - accuracy: 0.7177 - val_loss: 1.0344 - val_accuracy: 0.6434\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7342 - accuracy: 0.7400 - val_loss: 1.0092 - val_accuracy: 0.6576\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6519 - accuracy: 0.7711 - val_loss: 1.0612 - val_accuracy: 0.6598\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5890 - accuracy: 0.7928 - val_loss: 1.0795 - val_accuracy: 0.6382\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5211 - accuracy: 0.8144 - val_loss: 1.1898 - val_accuracy: 0.6412\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4634 - accuracy: 0.8372 - val_loss: 1.2370 - val_accuracy: 0.6456\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3962 - accuracy: 0.8605 - val_loss: 1.3396 - val_accuracy: 0.6318\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3455 - accuracy: 0.8775 - val_loss: 1.4757 - val_accuracy: 0.6430\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3184 - accuracy: 0.8850 - val_loss: 1.5212 - val_accuracy: 0.6416\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2700 - accuracy: 0.9029 - val_loss: 1.6683 - val_accuracy: 0.6344\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2406 - accuracy: 0.9139 - val_loss: 1.7824 - val_accuracy: 0.6310\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 0.2092 - accuracy: 0.9252 - val_loss: 1.9439 - val_accuracy: 0.6316\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2011 - accuracy: 0.9276 - val_loss: 2.1808 - val_accuracy: 0.6194\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1816 - accuracy: 0.9349 - val_loss: 2.1868 - val_accuracy: 0.6260\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1756 - accuracy: 0.9386 - val_loss: 2.2763 - val_accuracy: 0.6240\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1591 - accuracy: 0.9431 - val_loss: 2.3676 - val_accuracy: 0.6280\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1486 - accuracy: 0.9486 - val_loss: 2.5188 - val_accuracy: 0.6256\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1422 - accuracy: 0.9501 - val_loss: 2.5540 - val_accuracy: 0.6226\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1417 - accuracy: 0.9512 - val_loss: 2.7166 - val_accuracy: 0.6284\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1269 - accuracy: 0.9558 - val_loss: 2.6708 - val_accuracy: 0.6288\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3453 - accuracy: 0.9367\n",
            "Test loss: 0.34529000520706177\n",
            "Test accuracy: 0.936680018901825\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (1, 16, 16, 6)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_8 (Activation)   (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.5755 - accuracy: 0.4239 - val_loss: 1.2990 - val_accuracy: 0.5256\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2079 - accuracy: 0.5690 - val_loss: 1.2478 - val_accuracy: 0.5628\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0385 - accuracy: 0.6302 - val_loss: 1.0618 - val_accuracy: 0.6238\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8986 - accuracy: 0.6806 - val_loss: 1.0570 - val_accuracy: 0.6308\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7720 - accuracy: 0.7248 - val_loss: 1.0944 - val_accuracy: 0.6392\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6469 - accuracy: 0.7695 - val_loss: 1.2054 - val_accuracy: 0.6352\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5421 - accuracy: 0.8045 - val_loss: 1.1543 - val_accuracy: 0.6520\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4302 - accuracy: 0.8464 - val_loss: 1.3177 - val_accuracy: 0.6348\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3578 - accuracy: 0.8724 - val_loss: 1.5266 - val_accuracy: 0.6268\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2838 - accuracy: 0.8995 - val_loss: 1.7177 - val_accuracy: 0.6324\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2400 - accuracy: 0.9156 - val_loss: 1.8708 - val_accuracy: 0.6250\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2087 - accuracy: 0.9257 - val_loss: 1.9440 - val_accuracy: 0.6316\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1865 - accuracy: 0.9348 - val_loss: 2.2028 - val_accuracy: 0.6224\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1815 - accuracy: 0.9386 - val_loss: 2.2654 - val_accuracy: 0.6216\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1808 - accuracy: 0.9372 - val_loss: 2.3403 - val_accuracy: 0.6140\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1451 - accuracy: 0.9512 - val_loss: 2.5939 - val_accuracy: 0.6274\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1472 - accuracy: 0.9501 - val_loss: 2.6287 - val_accuracy: 0.6248\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1278 - accuracy: 0.9584 - val_loss: 2.7105 - val_accuracy: 0.6200\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1315 - accuracy: 0.9554 - val_loss: 2.9401 - val_accuracy: 0.6208\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1369 - accuracy: 0.9558 - val_loss: 2.7767 - val_accuracy: 0.6150\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1123 - accuracy: 0.9622 - val_loss: 3.1117 - val_accuracy: 0.6096\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1399 - accuracy: 0.9553 - val_loss: 2.8013 - val_accuracy: 0.6224\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1368 - accuracy: 0.9558 - val_loss: 3.1947 - val_accuracy: 0.6266\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1206 - accuracy: 0.9609 - val_loss: 3.0092 - val_accuracy: 0.6086\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1128 - accuracy: 0.9643 - val_loss: 3.0865 - val_accuracy: 0.6076\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4019 - accuracy: 0.9291\n",
            "Test loss: 0.40189558267593384\n",
            "Test accuracy: 0.929099977016449\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_10 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_11 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.5999 - accuracy: 0.4158 - val_loss: 1.3860 - val_accuracy: 0.4978\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2518 - accuracy: 0.5538 - val_loss: 1.2167 - val_accuracy: 0.5572\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1016 - accuracy: 0.6074 - val_loss: 1.0966 - val_accuracy: 0.6148\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9922 - accuracy: 0.6467 - val_loss: 1.1376 - val_accuracy: 0.5988\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8962 - accuracy: 0.6823 - val_loss: 1.1570 - val_accuracy: 0.6038\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8395 - accuracy: 0.7010 - val_loss: 1.0852 - val_accuracy: 0.6290\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7393 - accuracy: 0.7363 - val_loss: 1.1639 - val_accuracy: 0.6170\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6765 - accuracy: 0.7577 - val_loss: 1.2199 - val_accuracy: 0.6122\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6082 - accuracy: 0.7829 - val_loss: 1.3097 - val_accuracy: 0.6092\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.5585 - accuracy: 0.7983 - val_loss: 1.4411 - val_accuracy: 0.6000\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4830 - accuracy: 0.8280 - val_loss: 1.5259 - val_accuracy: 0.6138\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4241 - accuracy: 0.8467 - val_loss: 1.6955 - val_accuracy: 0.6038\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3920 - accuracy: 0.8602 - val_loss: 1.7439 - val_accuracy: 0.6114\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3590 - accuracy: 0.8712 - val_loss: 1.9619 - val_accuracy: 0.5928\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3281 - accuracy: 0.8842 - val_loss: 1.9910 - val_accuracy: 0.5920\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2801 - accuracy: 0.8991 - val_loss: 2.2346 - val_accuracy: 0.6034\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2956 - accuracy: 0.8961 - val_loss: 2.2791 - val_accuracy: 0.6018\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2779 - accuracy: 0.9018 - val_loss: 2.3851 - val_accuracy: 0.6024\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2350 - accuracy: 0.9145 - val_loss: 2.5843 - val_accuracy: 0.5948\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2444 - accuracy: 0.9140 - val_loss: 2.6283 - val_accuracy: 0.5938\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2089 - accuracy: 0.9262 - val_loss: 2.8730 - val_accuracy: 0.5908\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2123 - accuracy: 0.9255 - val_loss: 2.7604 - val_accuracy: 0.5864\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2117 - accuracy: 0.9277 - val_loss: 2.9941 - val_accuracy: 0.5894\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1911 - accuracy: 0.9343 - val_loss: 3.0446 - val_accuracy: 0.5946\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2112 - accuracy: 0.9285 - val_loss: 3.0909 - val_accuracy: 0.5866\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4628 - accuracy: 0.9062\n",
            "Test loss: 0.46280166506767273\n",
            "Test accuracy: 0.9061999917030334\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_12 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_13 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 1.8287 - accuracy: 0.3194 - val_loss: 1.5429 - val_accuracy: 0.4354\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4619 - accuracy: 0.4702 - val_loss: 1.3787 - val_accuracy: 0.4998\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3173 - accuracy: 0.5278 - val_loss: 1.3053 - val_accuracy: 0.5288\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2348 - accuracy: 0.5605 - val_loss: 1.3320 - val_accuracy: 0.5272\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1604 - accuracy: 0.5874 - val_loss: 1.2551 - val_accuracy: 0.5542\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0998 - accuracy: 0.6085 - val_loss: 1.2507 - val_accuracy: 0.5606\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0373 - accuracy: 0.6279 - val_loss: 1.2595 - val_accuracy: 0.5632\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.9856 - accuracy: 0.6487 - val_loss: 1.2856 - val_accuracy: 0.5592\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.9502 - accuracy: 0.6626 - val_loss: 1.3475 - val_accuracy: 0.5562\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9065 - accuracy: 0.6790 - val_loss: 1.3366 - val_accuracy: 0.5636\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8594 - accuracy: 0.6943 - val_loss: 1.3992 - val_accuracy: 0.5446\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8262 - accuracy: 0.7058 - val_loss: 1.3749 - val_accuracy: 0.5500\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7786 - accuracy: 0.7222 - val_loss: 1.4636 - val_accuracy: 0.5438\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7417 - accuracy: 0.7345 - val_loss: 1.5451 - val_accuracy: 0.5386\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7251 - accuracy: 0.7422 - val_loss: 1.5883 - val_accuracy: 0.5412\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7065 - accuracy: 0.7478 - val_loss: 1.7222 - val_accuracy: 0.5168\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6754 - accuracy: 0.7572 - val_loss: 1.6913 - val_accuracy: 0.5394\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 0.6458 - accuracy: 0.7666 - val_loss: 1.7271 - val_accuracy: 0.5364\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 0.6034 - accuracy: 0.7827 - val_loss: 1.8331 - val_accuracy: 0.5344\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5929 - accuracy: 0.7855 - val_loss: 2.1013 - val_accuracy: 0.4980\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5757 - accuracy: 0.7930 - val_loss: 1.9759 - val_accuracy: 0.5234\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5565 - accuracy: 0.8021 - val_loss: 1.9528 - val_accuracy: 0.5218\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5454 - accuracy: 0.8039 - val_loss: 2.1123 - val_accuracy: 0.5338\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5156 - accuracy: 0.8149 - val_loss: 2.2122 - val_accuracy: 0.5272\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5029 - accuracy: 0.8194 - val_loss: 2.1739 - val_accuracy: 0.5272\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5805 - accuracy: 0.8218\n",
            "Test loss: 0.5805073976516724\n",
            "Test accuracy: 0.8217999935150146\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_21 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 2.3347 - accuracy: 0.1036 - val_loss: 2.3038 - val_accuracy: 0.0958\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3032 - val_accuracy: 0.1064\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.0966 - val_loss: 2.3027 - val_accuracy: 0.0986\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3030 - accuracy: 0.0999 - val_loss: 2.3037 - val_accuracy: 0.0950\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3030 - accuracy: 0.1013 - val_loss: 2.3035 - val_accuracy: 0.0970\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.0982 - val_loss: 2.3029 - val_accuracy: 0.0976\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.1009 - val_loss: 2.3031 - val_accuracy: 0.1038\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.1058\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0990 - val_loss: 2.3032 - val_accuracy: 0.0976\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3030 - accuracy: 0.1015 - val_loss: 2.3031 - val_accuracy: 0.1058\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.1000 - val_loss: 2.3031 - val_accuracy: 0.0950\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.1064\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.1015 - val_loss: 2.3029 - val_accuracy: 0.1064\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.0976\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.0989 - val_loss: 2.3036 - val_accuracy: 0.1024\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0979 - val_loss: 2.3024 - val_accuracy: 0.1064\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.1002 - val_loss: 2.3031 - val_accuracy: 0.0950\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0987 - val_loss: 2.3032 - val_accuracy: 0.1058\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.1038\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.0997 - val_loss: 2.3035 - val_accuracy: 0.0970\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0998 - val_loss: 2.3035 - val_accuracy: 0.0976\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.0976\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3031 - accuracy: 0.0996 - val_loss: 2.3034 - val_accuracy: 0.0976\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3033 - accuracy: 0.0987 - val_loss: 2.3031 - val_accuracy: 0.0958\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3032 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1064\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.3030 - accuracy: 0.1000\n",
            "Test loss: 2.303006172180176\n",
            "Test accuracy: 0.10000000149011612\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_16 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 8ms/step - loss: 1.8596 - accuracy: 0.3211 - val_loss: 1.6534 - val_accuracy: 0.3930\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 1.5853 - accuracy: 0.4322 - val_loss: 1.5610 - val_accuracy: 0.4464\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4965 - accuracy: 0.4647 - val_loss: 1.6249 - val_accuracy: 0.4252\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.4215 - accuracy: 0.4903 - val_loss: 1.4469 - val_accuracy: 0.4854\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3800 - accuracy: 0.5069 - val_loss: 1.4318 - val_accuracy: 0.4854\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.3412 - accuracy: 0.5190 - val_loss: 1.4127 - val_accuracy: 0.5028\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2891 - accuracy: 0.5416 - val_loss: 1.4820 - val_accuracy: 0.4848\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 1.2671 - accuracy: 0.5493 - val_loss: 1.4212 - val_accuracy: 0.5028\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2441 - accuracy: 0.5582 - val_loss: 1.4491 - val_accuracy: 0.4990\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2306 - accuracy: 0.5623 - val_loss: 1.4342 - val_accuracy: 0.5072\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.2076 - accuracy: 0.5676 - val_loss: 1.4559 - val_accuracy: 0.4974\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1912 - accuracy: 0.5787 - val_loss: 1.4683 - val_accuracy: 0.4940\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 1.1570 - accuracy: 0.5886 - val_loss: 1.5310 - val_accuracy: 0.4834\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1613 - accuracy: 0.5879 - val_loss: 1.5755 - val_accuracy: 0.4774\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1399 - accuracy: 0.5959 - val_loss: 1.5260 - val_accuracy: 0.4914\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1276 - accuracy: 0.5953 - val_loss: 1.4892 - val_accuracy: 0.4996\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1048 - accuracy: 0.6063 - val_loss: 1.5247 - val_accuracy: 0.4952\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0956 - accuracy: 0.6092 - val_loss: 1.5319 - val_accuracy: 0.5014\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0884 - accuracy: 0.6116 - val_loss: 1.6680 - val_accuracy: 0.4590\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0842 - accuracy: 0.6143 - val_loss: 1.5878 - val_accuracy: 0.4964\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0717 - accuracy: 0.6163 - val_loss: 1.6065 - val_accuracy: 0.4958\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0759 - accuracy: 0.6162 - val_loss: 1.7096 - val_accuracy: 0.4584\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0628 - accuracy: 0.6210 - val_loss: 1.7065 - val_accuracy: 0.4620\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0463 - accuracy: 0.6286 - val_loss: 1.6966 - val_accuracy: 0.4856\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0427 - accuracy: 0.6287 - val_loss: 1.6393 - val_accuracy: 0.4824\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0004 - accuracy: 0.6461\n",
            "Test loss: 1.0003684759140015\n",
            "Test accuracy: 0.6461399793624878\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_27 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_18 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_19 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 4s 9ms/step - loss: 2.6359 - accuracy: 0.1008 - val_loss: 2.3046 - val_accuracy: 0.0958\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1001 - val_loss: 2.3038 - val_accuracy: 0.0950\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3046 - accuracy: 0.0981 - val_loss: 2.3035 - val_accuracy: 0.0986\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.0999 - val_loss: 2.3042 - val_accuracy: 0.0986\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1019 - val_loss: 2.3039 - val_accuracy: 0.0986\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.1025 - val_loss: 2.3034 - val_accuracy: 0.0958\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.1016 - val_loss: 2.3031 - val_accuracy: 0.1038\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3037 - accuracy: 0.1014 - val_loss: 2.3045 - val_accuracy: 0.0958\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3044 - accuracy: 0.0990 - val_loss: 2.3031 - val_accuracy: 0.0976\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.0982 - val_loss: 2.3041 - val_accuracy: 0.1038\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 2.3042 - accuracy: 0.0994 - val_loss: 2.3049 - val_accuracy: 0.0976\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3043 - accuracy: 0.1000 - val_loss: 2.3047 - val_accuracy: 0.0986\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.0996 - val_loss: 2.3069 - val_accuracy: 0.0950\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0995 - val_loss: 2.3043 - val_accuracy: 0.1024\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.1002 - val_loss: 2.3044 - val_accuracy: 0.1024\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3043 - accuracy: 0.0999 - val_loss: 2.3068 - val_accuracy: 0.0976\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3043 - accuracy: 0.0988 - val_loss: 2.3049 - val_accuracy: 0.0976\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3047 - accuracy: 0.0982 - val_loss: 2.3042 - val_accuracy: 0.1024\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1005 - val_loss: 2.3042 - val_accuracy: 0.0970\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3043 - accuracy: 0.1008 - val_loss: 2.3026 - val_accuracy: 0.1038\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.1002 - val_loss: 2.3043 - val_accuracy: 0.0970\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3044 - accuracy: 0.0998 - val_loss: 2.3030 - val_accuracy: 0.1038\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3039 - accuracy: 0.1019 - val_loss: 2.3044 - val_accuracy: 0.0976\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3041 - accuracy: 0.1018 - val_loss: 2.3053 - val_accuracy: 0.0950\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3042 - accuracy: 0.0999 - val_loss: 2.3041 - val_accuracy: 0.1024\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3041 - accuracy: 0.1000\n",
            "Test loss: 2.3041372299194336\n",
            "Test accuracy: 0.10000000149011612\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_20 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_21 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "352/352 [==============================] - 3s 7ms/step - loss: 7.1772 - accuracy: 0.0996 - val_loss: 2.3042 - val_accuracy: 0.1024\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.0991 - val_loss: 2.3057 - val_accuracy: 0.1024\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.0992 - val_loss: 2.3064 - val_accuracy: 0.1064\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.1019 - val_loss: 2.3041 - val_accuracy: 0.1038\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3061 - accuracy: 0.0992 - val_loss: 2.3027 - val_accuracy: 0.1058\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3054 - accuracy: 0.0998 - val_loss: 2.3058 - val_accuracy: 0.0950\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3061 - accuracy: 0.1005 - val_loss: 2.3034 - val_accuracy: 0.1038\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3060 - accuracy: 0.0999 - val_loss: 2.3063 - val_accuracy: 0.1064\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3064 - accuracy: 0.0956 - val_loss: 2.3034 - val_accuracy: 0.0970\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.0990 - val_loss: 2.3107 - val_accuracy: 0.0976\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3054 - accuracy: 0.1012 - val_loss: 2.3040 - val_accuracy: 0.0958\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3059 - accuracy: 0.1008 - val_loss: 2.3052 - val_accuracy: 0.1024\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3059 - accuracy: 0.0986 - val_loss: 2.3052 - val_accuracy: 0.0976\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.0978 - val_loss: 2.3050 - val_accuracy: 0.0970\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3060 - accuracy: 0.0974 - val_loss: 2.3070 - val_accuracy: 0.0976\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3055 - accuracy: 0.0998 - val_loss: 2.3053 - val_accuracy: 0.0970\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3065 - accuracy: 0.0962 - val_loss: 2.3079 - val_accuracy: 0.0986\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1003 - val_loss: 2.3037 - val_accuracy: 0.0976\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.0984 - val_loss: 2.3063 - val_accuracy: 0.1024\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3060 - accuracy: 0.0999 - val_loss: 2.3066 - val_accuracy: 0.0976\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3057 - accuracy: 0.0992 - val_loss: 2.3056 - val_accuracy: 0.0970\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3057 - accuracy: 0.1009 - val_loss: 2.3050 - val_accuracy: 0.1064\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3056 - accuracy: 0.1012 - val_loss: 2.3059 - val_accuracy: 0.0958\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 7ms/step - loss: 2.3061 - accuracy: 0.0987 - val_loss: 2.3040 - val_accuracy: 0.0976\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 2.3058 - accuracy: 0.0987 - val_loss: 2.3050 - val_accuracy: 0.0970\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3047 - accuracy: 0.1000\n",
            "Test loss: 2.3046672344207764\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the accuracy of different learning rate\n",
        "a = range(len(lr_list))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(a, Accuracy, \"*\")\n",
        "#plt.scatter(a, Accuracy)\n",
        "\n",
        "ax.set_xticks(a)\n",
        "ax.set_xticklabels(lr_list)\n",
        "\n",
        "plt.xlabel('learning rate')\n",
        "plt.xlabel('accuracy')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "B4DPESC6HH3R",
        "outputId": "036d5f6c-e9f4-4df4-ef1a-677a3366fcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The effect of batch size"
      ],
      "metadata": {
        "id": "kCzv_dssYZXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize_list = [20, 40, 60, 80,100,120,150,200]\n",
        "\n",
        "lr = 0.002\n",
        "Accuracy2 = []\n",
        "for batch_size in batchsize_list:\n",
        "  # Build a LeNet Convolutional Neural Network\n",
        "\n",
        "  cnn_model = keras.Sequential()\n",
        "  #layer 1-2\n",
        "  cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 3-4\n",
        "  cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "  cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  #layer 5\n",
        "  cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "  #flatten 2d data to 1d\n",
        "  cnn_model.add(keras.layers.Flatten())\n",
        "  #layer 6\n",
        "  cnn_model.add(keras.layers.Dense(84))\n",
        "  cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "  # layer 7 output layer\n",
        "  cnn_model.add(keras.layers.Dense(n_class))\n",
        "  cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "  cnn_model.build(input_shape=(1,32,32,3))\n",
        "  # print summary of the model\n",
        "  cnn_model.summary()\n",
        "\n",
        "  # train the model\n",
        "  epochs = 25\n",
        "  #batch_size = 128\n",
        "\n",
        "  #define the optimizer\n",
        "  opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "  # compile the model\n",
        "  cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  # train the model\n",
        "  cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  # Evaluate\n",
        "  score = cnn_model.evaluate(image_train, class_train)\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "  Accuracy2.append(score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpzDTEHVODrl",
        "outputId": "bd9e2afb-72d3-4b41-eeb5-68273565524a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_33 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_22 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_23 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 1.6104 - accuracy: 0.4129 - val_loss: 1.3343 - val_accuracy: 0.5326\n",
            "Epoch 2/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.2645 - accuracy: 0.5514 - val_loss: 1.1694 - val_accuracy: 0.5808\n",
            "Epoch 3/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 1.1248 - accuracy: 0.6027 - val_loss: 1.1502 - val_accuracy: 0.6020\n",
            "Epoch 4/25\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 1.0315 - accuracy: 0.6370 - val_loss: 1.0983 - val_accuracy: 0.6212\n",
            "Epoch 5/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.9455 - accuracy: 0.6687 - val_loss: 1.0864 - val_accuracy: 0.6190\n",
            "Epoch 6/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.8756 - accuracy: 0.6912 - val_loss: 1.1536 - val_accuracy: 0.6128\n",
            "Epoch 7/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.7942 - accuracy: 0.7198 - val_loss: 1.1804 - val_accuracy: 0.6112\n",
            "Epoch 8/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.7263 - accuracy: 0.7441 - val_loss: 1.2206 - val_accuracy: 0.6056\n",
            "Epoch 9/25\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.6611 - accuracy: 0.7673 - val_loss: 1.3198 - val_accuracy: 0.6046\n",
            "Epoch 10/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.5910 - accuracy: 0.7903 - val_loss: 1.3696 - val_accuracy: 0.5994\n",
            "Epoch 11/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.5347 - accuracy: 0.8109 - val_loss: 1.5552 - val_accuracy: 0.5960\n",
            "Epoch 12/25\n",
            "2250/2250 [==============================] - 10s 4ms/step - loss: 0.4909 - accuracy: 0.8269 - val_loss: 1.6515 - val_accuracy: 0.5970\n",
            "Epoch 13/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.4463 - accuracy: 0.8413 - val_loss: 1.7471 - val_accuracy: 0.5980\n",
            "Epoch 14/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.4047 - accuracy: 0.8566 - val_loss: 1.9074 - val_accuracy: 0.5818\n",
            "Epoch 15/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3722 - accuracy: 0.8679 - val_loss: 2.0335 - val_accuracy: 0.5924\n",
            "Epoch 16/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3478 - accuracy: 0.8792 - val_loss: 2.2417 - val_accuracy: 0.5934\n",
            "Epoch 17/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.3294 - accuracy: 0.8855 - val_loss: 2.2308 - val_accuracy: 0.5904\n",
            "Epoch 18/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2980 - accuracy: 0.8953 - val_loss: 2.4830 - val_accuracy: 0.5828\n",
            "Epoch 19/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2842 - accuracy: 0.9008 - val_loss: 2.5052 - val_accuracy: 0.5778\n",
            "Epoch 20/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2708 - accuracy: 0.9073 - val_loss: 2.5629 - val_accuracy: 0.5800\n",
            "Epoch 21/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2606 - accuracy: 0.9114 - val_loss: 2.7934 - val_accuracy: 0.5802\n",
            "Epoch 22/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2595 - accuracy: 0.9124 - val_loss: 2.8098 - val_accuracy: 0.5754\n",
            "Epoch 23/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2403 - accuracy: 0.9199 - val_loss: 3.1115 - val_accuracy: 0.5862\n",
            "Epoch 24/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2429 - accuracy: 0.9199 - val_loss: 3.1002 - val_accuracy: 0.5710\n",
            "Epoch 25/25\n",
            "2250/2250 [==============================] - 9s 4ms/step - loss: 0.2218 - accuracy: 0.9254 - val_loss: 3.2322 - val_accuracy: 0.5754\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4800 - accuracy: 0.9039\n",
            "Test loss: 0.479963481426239\n",
            "Test accuracy: 0.9039199948310852\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_24 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_25 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "1125/1125 [==============================] - 6s 5ms/step - loss: 1.5574 - accuracy: 0.4338 - val_loss: 1.3044 - val_accuracy: 0.5284\n",
            "Epoch 2/25\n",
            "1125/1125 [==============================] - 5s 5ms/step - loss: 1.1989 - accuracy: 0.5749 - val_loss: 1.1067 - val_accuracy: 0.5972\n",
            "Epoch 3/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 1.0306 - accuracy: 0.6322 - val_loss: 1.0246 - val_accuracy: 0.6400\n",
            "Epoch 4/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.9053 - accuracy: 0.6803 - val_loss: 1.0340 - val_accuracy: 0.6394\n",
            "Epoch 5/25\n",
            "1125/1125 [==============================] - 6s 5ms/step - loss: 0.7893 - accuracy: 0.7192 - val_loss: 1.0527 - val_accuracy: 0.6394\n",
            "Epoch 6/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.6850 - accuracy: 0.7573 - val_loss: 1.0829 - val_accuracy: 0.6520\n",
            "Epoch 7/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.5864 - accuracy: 0.7932 - val_loss: 1.2066 - val_accuracy: 0.6324\n",
            "Epoch 8/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.5027 - accuracy: 0.8221 - val_loss: 1.3066 - val_accuracy: 0.6288\n",
            "Epoch 9/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.4243 - accuracy: 0.8489 - val_loss: 1.3839 - val_accuracy: 0.6384\n",
            "Epoch 10/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.3687 - accuracy: 0.8686 - val_loss: 1.5937 - val_accuracy: 0.6350\n",
            "Epoch 11/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.3254 - accuracy: 0.8838 - val_loss: 1.6770 - val_accuracy: 0.6274\n",
            "Epoch 12/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2715 - accuracy: 0.9057 - val_loss: 1.9116 - val_accuracy: 0.6174\n",
            "Epoch 13/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2649 - accuracy: 0.9082 - val_loss: 1.9982 - val_accuracy: 0.6122\n",
            "Epoch 14/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2266 - accuracy: 0.9203 - val_loss: 2.1672 - val_accuracy: 0.6224\n",
            "Epoch 15/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2216 - accuracy: 0.9240 - val_loss: 2.3387 - val_accuracy: 0.6174\n",
            "Epoch 16/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.2170 - accuracy: 0.9256 - val_loss: 2.4643 - val_accuracy: 0.6204\n",
            "Epoch 17/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1802 - accuracy: 0.9375 - val_loss: 2.6085 - val_accuracy: 0.6112\n",
            "Epoch 18/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1925 - accuracy: 0.9353 - val_loss: 2.5504 - val_accuracy: 0.6170\n",
            "Epoch 19/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1791 - accuracy: 0.9393 - val_loss: 2.7957 - val_accuracy: 0.6090\n",
            "Epoch 20/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1648 - accuracy: 0.9453 - val_loss: 2.8522 - val_accuracy: 0.6074\n",
            "Epoch 21/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1817 - accuracy: 0.9431 - val_loss: 2.6978 - val_accuracy: 0.6130\n",
            "Epoch 22/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1687 - accuracy: 0.9457 - val_loss: 2.8347 - val_accuracy: 0.6054\n",
            "Epoch 23/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1514 - accuracy: 0.9512 - val_loss: 2.9304 - val_accuracy: 0.6064\n",
            "Epoch 24/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1532 - accuracy: 0.9517 - val_loss: 3.1643 - val_accuracy: 0.6068\n",
            "Epoch 25/25\n",
            "1125/1125 [==============================] - 5s 4ms/step - loss: 0.1469 - accuracy: 0.9524 - val_loss: 3.1562 - val_accuracy: 0.6114\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4069 - accuracy: 0.9320\n",
            "Test loss: 0.4068524241447449\n",
            "Test accuracy: 0.9319599866867065\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_39 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_26 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_27 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 1.5742 - accuracy: 0.4215 - val_loss: 1.2556 - val_accuracy: 0.5496\n",
            "Epoch 2/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 1.1682 - accuracy: 0.5852 - val_loss: 1.1275 - val_accuracy: 0.5986\n",
            "Epoch 3/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.9941 - accuracy: 0.6508 - val_loss: 1.0846 - val_accuracy: 0.6262\n",
            "Epoch 4/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.8692 - accuracy: 0.6939 - val_loss: 1.0129 - val_accuracy: 0.6486\n",
            "Epoch 5/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.7503 - accuracy: 0.7336 - val_loss: 0.9863 - val_accuracy: 0.6638\n",
            "Epoch 6/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.6478 - accuracy: 0.7713 - val_loss: 1.0144 - val_accuracy: 0.6718\n",
            "Epoch 7/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5441 - accuracy: 0.8086 - val_loss: 1.0882 - val_accuracy: 0.6604\n",
            "Epoch 8/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.4597 - accuracy: 0.8363 - val_loss: 1.2197 - val_accuracy: 0.6480\n",
            "Epoch 9/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.3922 - accuracy: 0.8608 - val_loss: 1.4490 - val_accuracy: 0.6414\n",
            "Epoch 10/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3311 - accuracy: 0.8833 - val_loss: 1.4652 - val_accuracy: 0.6368\n",
            "Epoch 11/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2702 - accuracy: 0.9036 - val_loss: 1.6669 - val_accuracy: 0.6362\n",
            "Epoch 12/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2478 - accuracy: 0.9137 - val_loss: 1.7589 - val_accuracy: 0.6456\n",
            "Epoch 13/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2191 - accuracy: 0.9226 - val_loss: 1.9011 - val_accuracy: 0.6422\n",
            "Epoch 14/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1990 - accuracy: 0.9312 - val_loss: 2.0516 - val_accuracy: 0.6394\n",
            "Epoch 15/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1773 - accuracy: 0.9382 - val_loss: 2.1413 - val_accuracy: 0.6304\n",
            "Epoch 16/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1685 - accuracy: 0.9412 - val_loss: 2.3519 - val_accuracy: 0.6374\n",
            "Epoch 17/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1715 - accuracy: 0.9418 - val_loss: 2.3706 - val_accuracy: 0.6400\n",
            "Epoch 18/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.1531 - accuracy: 0.9473 - val_loss: 2.4087 - val_accuracy: 0.6288\n",
            "Epoch 19/25\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1620 - accuracy: 0.9432 - val_loss: 2.5700 - val_accuracy: 0.6260\n",
            "Epoch 20/25\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.1475 - accuracy: 0.9500 - val_loss: 2.5850 - val_accuracy: 0.6318\n",
            "Epoch 21/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1418 - accuracy: 0.9534 - val_loss: 2.7318 - val_accuracy: 0.6218\n",
            "Epoch 22/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.9528 - val_loss: 2.6424 - val_accuracy: 0.6266\n",
            "Epoch 23/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.1150 - accuracy: 0.9622 - val_loss: 2.7141 - val_accuracy: 0.6226\n",
            "Epoch 24/25\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.1240 - accuracy: 0.9589 - val_loss: 2.8107 - val_accuracy: 0.6278\n",
            "Epoch 25/25\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.1241 - accuracy: 0.9596 - val_loss: 3.1044 - val_accuracy: 0.6240\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4597 - accuracy: 0.9172\n",
            "Test loss: 0.45974430441856384\n",
            "Test accuracy: 0.9172000288963318\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_28 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_29 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "563/563 [==============================] - 4s 6ms/step - loss: 1.6581 - accuracy: 0.3878 - val_loss: 1.3547 - val_accuracy: 0.5110\n",
            "Epoch 2/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 1.2612 - accuracy: 0.5486 - val_loss: 1.1964 - val_accuracy: 0.5698\n",
            "Epoch 3/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 1.1021 - accuracy: 0.6102 - val_loss: 1.0673 - val_accuracy: 0.6290\n",
            "Epoch 4/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.9906 - accuracy: 0.6504 - val_loss: 1.0299 - val_accuracy: 0.6366\n",
            "Epoch 5/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.8948 - accuracy: 0.6862 - val_loss: 1.0487 - val_accuracy: 0.6388\n",
            "Epoch 6/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.8133 - accuracy: 0.7129 - val_loss: 1.0233 - val_accuracy: 0.6520\n",
            "Epoch 7/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.7413 - accuracy: 0.7365 - val_loss: 1.0009 - val_accuracy: 0.6628\n",
            "Epoch 8/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.6646 - accuracy: 0.7653 - val_loss: 1.0594 - val_accuracy: 0.6558\n",
            "Epoch 9/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.5956 - accuracy: 0.7866 - val_loss: 1.0802 - val_accuracy: 0.6540\n",
            "Epoch 10/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.5301 - accuracy: 0.8109 - val_loss: 1.2331 - val_accuracy: 0.6488\n",
            "Epoch 11/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.4727 - accuracy: 0.8311 - val_loss: 1.2432 - val_accuracy: 0.6382\n",
            "Epoch 12/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.4149 - accuracy: 0.8506 - val_loss: 1.3306 - val_accuracy: 0.6464\n",
            "Epoch 13/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.3627 - accuracy: 0.8703 - val_loss: 1.5085 - val_accuracy: 0.6456\n",
            "Epoch 14/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.3220 - accuracy: 0.8836 - val_loss: 1.5507 - val_accuracy: 0.6408\n",
            "Epoch 15/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2953 - accuracy: 0.8942 - val_loss: 1.7154 - val_accuracy: 0.6336\n",
            "Epoch 16/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.2526 - accuracy: 0.9079 - val_loss: 1.8586 - val_accuracy: 0.6244\n",
            "Epoch 17/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.2530 - accuracy: 0.9092 - val_loss: 1.9038 - val_accuracy: 0.6226\n",
            "Epoch 18/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.2121 - accuracy: 0.9256 - val_loss: 2.0836 - val_accuracy: 0.6200\n",
            "Epoch 19/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.2052 - accuracy: 0.9271 - val_loss: 2.2449 - val_accuracy: 0.6244\n",
            "Epoch 20/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.1875 - accuracy: 0.9337 - val_loss: 2.2400 - val_accuracy: 0.6178\n",
            "Epoch 21/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.1715 - accuracy: 0.9390 - val_loss: 2.3536 - val_accuracy: 0.6236\n",
            "Epoch 22/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.1564 - accuracy: 0.9449 - val_loss: 2.5676 - val_accuracy: 0.6270\n",
            "Epoch 23/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1647 - accuracy: 0.9430 - val_loss: 2.5932 - val_accuracy: 0.6228\n",
            "Epoch 24/25\n",
            "563/563 [==============================] - 3s 5ms/step - loss: 0.1550 - accuracy: 0.9458 - val_loss: 2.6692 - val_accuracy: 0.6194\n",
            "Epoch 25/25\n",
            "563/563 [==============================] - 3s 6ms/step - loss: 0.1559 - accuracy: 0.9460 - val_loss: 2.8050 - val_accuracy: 0.6174\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4257 - accuracy: 0.9110\n",
            "Test loss: 0.4256749153137207\n",
            "Test accuracy: 0.9109600186347961\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_45 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_30 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_31 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "450/450 [==============================] - 3s 6ms/step - loss: 1.6569 - accuracy: 0.3936 - val_loss: 1.4386 - val_accuracy: 0.4738\n",
            "Epoch 2/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 1.2717 - accuracy: 0.5459 - val_loss: 1.1745 - val_accuracy: 0.5758\n",
            "Epoch 3/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 1.1024 - accuracy: 0.6096 - val_loss: 1.1073 - val_accuracy: 0.6108\n",
            "Epoch 4/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.9676 - accuracy: 0.6601 - val_loss: 1.0476 - val_accuracy: 0.6318\n",
            "Epoch 5/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.8600 - accuracy: 0.6990 - val_loss: 1.0407 - val_accuracy: 0.6458\n",
            "Epoch 6/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.7441 - accuracy: 0.7399 - val_loss: 1.0906 - val_accuracy: 0.6430\n",
            "Epoch 7/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.6438 - accuracy: 0.7733 - val_loss: 1.0705 - val_accuracy: 0.6548\n",
            "Epoch 8/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.5432 - accuracy: 0.8086 - val_loss: 1.2168 - val_accuracy: 0.6372\n",
            "Epoch 9/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.4637 - accuracy: 0.8370 - val_loss: 1.2576 - val_accuracy: 0.6444\n",
            "Epoch 10/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.3719 - accuracy: 0.8676 - val_loss: 1.4162 - val_accuracy: 0.6354\n",
            "Epoch 11/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.3186 - accuracy: 0.8877 - val_loss: 1.5217 - val_accuracy: 0.6330\n",
            "Epoch 12/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2743 - accuracy: 0.9048 - val_loss: 1.6697 - val_accuracy: 0.6274\n",
            "Epoch 13/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2169 - accuracy: 0.9238 - val_loss: 1.8035 - val_accuracy: 0.6374\n",
            "Epoch 14/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.2060 - accuracy: 0.9262 - val_loss: 2.0139 - val_accuracy: 0.6234\n",
            "Epoch 15/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1776 - accuracy: 0.9382 - val_loss: 2.2636 - val_accuracy: 0.6232\n",
            "Epoch 16/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1677 - accuracy: 0.9417 - val_loss: 2.1915 - val_accuracy: 0.6206\n",
            "Epoch 17/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1577 - accuracy: 0.9446 - val_loss: 2.4278 - val_accuracy: 0.6196\n",
            "Epoch 18/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1352 - accuracy: 0.9530 - val_loss: 2.5524 - val_accuracy: 0.6172\n",
            "Epoch 19/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1399 - accuracy: 0.9513 - val_loss: 2.5571 - val_accuracy: 0.6252\n",
            "Epoch 20/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1442 - accuracy: 0.9503 - val_loss: 2.7642 - val_accuracy: 0.6234\n",
            "Epoch 21/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1193 - accuracy: 0.9593 - val_loss: 2.7414 - val_accuracy: 0.6160\n",
            "Epoch 22/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1241 - accuracy: 0.9578 - val_loss: 2.8296 - val_accuracy: 0.6226\n",
            "Epoch 23/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1039 - accuracy: 0.9653 - val_loss: 3.0649 - val_accuracy: 0.6162\n",
            "Epoch 24/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1184 - accuracy: 0.9614 - val_loss: 3.0584 - val_accuracy: 0.6192\n",
            "Epoch 25/25\n",
            "450/450 [==============================] - 2s 5ms/step - loss: 0.1071 - accuracy: 0.9637 - val_loss: 3.4012 - val_accuracy: 0.6138\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.4541 - accuracy: 0.9246\n",
            "Test loss: 0.45405834913253784\n",
            "Test accuracy: 0.9246199727058411\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_32 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_33 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 1.5774 - accuracy: 0.4290 - val_loss: 1.2954 - val_accuracy: 0.5338\n",
            "Epoch 2/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.2007 - accuracy: 0.5748 - val_loss: 1.0636 - val_accuracy: 0.6238\n",
            "Epoch 3/25\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0302 - accuracy: 0.6360 - val_loss: 1.0171 - val_accuracy: 0.6394\n",
            "Epoch 4/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.9019 - accuracy: 0.6823 - val_loss: 0.9797 - val_accuracy: 0.6656\n",
            "Epoch 5/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.7960 - accuracy: 0.7202 - val_loss: 0.9553 - val_accuracy: 0.6762\n",
            "Epoch 6/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6881 - accuracy: 0.7577 - val_loss: 0.9293 - val_accuracy: 0.6916\n",
            "Epoch 7/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5887 - accuracy: 0.7928 - val_loss: 1.0569 - val_accuracy: 0.6656\n",
            "Epoch 8/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4980 - accuracy: 0.8244 - val_loss: 1.0469 - val_accuracy: 0.6704\n",
            "Epoch 9/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4057 - accuracy: 0.8576 - val_loss: 1.1612 - val_accuracy: 0.6764\n",
            "Epoch 10/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3441 - accuracy: 0.8775 - val_loss: 1.2816 - val_accuracy: 0.6734\n",
            "Epoch 11/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2774 - accuracy: 0.9013 - val_loss: 1.4119 - val_accuracy: 0.6684\n",
            "Epoch 12/25\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2295 - accuracy: 0.9185 - val_loss: 1.5050 - val_accuracy: 0.6610\n",
            "Epoch 13/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.2016 - accuracy: 0.9278 - val_loss: 1.5925 - val_accuracy: 0.6584\n",
            "Epoch 14/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1663 - accuracy: 0.9408 - val_loss: 1.8282 - val_accuracy: 0.6574\n",
            "Epoch 15/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1563 - accuracy: 0.9443 - val_loss: 1.9575 - val_accuracy: 0.6558\n",
            "Epoch 16/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1387 - accuracy: 0.9517 - val_loss: 2.1557 - val_accuracy: 0.6524\n",
            "Epoch 17/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1386 - accuracy: 0.9511 - val_loss: 2.2472 - val_accuracy: 0.6554\n",
            "Epoch 18/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1475 - accuracy: 0.9488 - val_loss: 2.1288 - val_accuracy: 0.6452\n",
            "Epoch 19/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1206 - accuracy: 0.9583 - val_loss: 2.4103 - val_accuracy: 0.6480\n",
            "Epoch 20/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0958 - accuracy: 0.9671 - val_loss: 2.3707 - val_accuracy: 0.6420\n",
            "Epoch 21/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.1080 - accuracy: 0.9630 - val_loss: 2.5094 - val_accuracy: 0.6402\n",
            "Epoch 22/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1171 - accuracy: 0.9589 - val_loss: 2.4933 - val_accuracy: 0.6400\n",
            "Epoch 23/25\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1096 - accuracy: 0.9623 - val_loss: 2.8702 - val_accuracy: 0.6360\n",
            "Epoch 24/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0909 - accuracy: 0.9700 - val_loss: 2.8604 - val_accuracy: 0.6470\n",
            "Epoch 25/25\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 0.0976 - accuracy: 0.9676 - val_loss: 2.9341 - val_accuracy: 0.6456\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3621 - accuracy: 0.9424\n",
            "Test loss: 0.3621382415294647\n",
            "Test accuracy: 0.9423999786376953\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_51 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_34 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_35 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "300/300 [==============================] - 3s 7ms/step - loss: 1.7530 - accuracy: 0.3560 - val_loss: 1.4503 - val_accuracy: 0.4732\n",
            "Epoch 2/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3371 - accuracy: 0.5185 - val_loss: 1.2265 - val_accuracy: 0.5530\n",
            "Epoch 3/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1595 - accuracy: 0.5891 - val_loss: 1.1516 - val_accuracy: 0.5942\n",
            "Epoch 4/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0443 - accuracy: 0.6322 - val_loss: 1.0434 - val_accuracy: 0.6350\n",
            "Epoch 5/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.9450 - accuracy: 0.6658 - val_loss: 1.0158 - val_accuracy: 0.6422\n",
            "Epoch 6/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.8653 - accuracy: 0.6953 - val_loss: 0.9755 - val_accuracy: 0.6668\n",
            "Epoch 7/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.8067 - accuracy: 0.7160 - val_loss: 0.9943 - val_accuracy: 0.6652\n",
            "Epoch 8/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.7435 - accuracy: 0.7370 - val_loss: 0.9519 - val_accuracy: 0.6796\n",
            "Epoch 9/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.6842 - accuracy: 0.7599 - val_loss: 1.0568 - val_accuracy: 0.6530\n",
            "Epoch 10/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.6279 - accuracy: 0.7772 - val_loss: 0.9953 - val_accuracy: 0.6858\n",
            "Epoch 11/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5701 - accuracy: 0.7985 - val_loss: 1.0582 - val_accuracy: 0.6710\n",
            "Epoch 12/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.5288 - accuracy: 0.8126 - val_loss: 1.0719 - val_accuracy: 0.6780\n",
            "Epoch 13/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.4736 - accuracy: 0.8315 - val_loss: 1.1406 - val_accuracy: 0.6694\n",
            "Epoch 14/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.4171 - accuracy: 0.8506 - val_loss: 1.2409 - val_accuracy: 0.6696\n",
            "Epoch 15/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.3805 - accuracy: 0.8645 - val_loss: 1.2842 - val_accuracy: 0.6654\n",
            "Epoch 16/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.3407 - accuracy: 0.8784 - val_loss: 1.4006 - val_accuracy: 0.6644\n",
            "Epoch 17/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.3143 - accuracy: 0.8879 - val_loss: 1.4768 - val_accuracy: 0.6502\n",
            "Epoch 18/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.2811 - accuracy: 0.8989 - val_loss: 1.6783 - val_accuracy: 0.6326\n",
            "Epoch 19/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.2481 - accuracy: 0.9095 - val_loss: 1.7048 - val_accuracy: 0.6528\n",
            "Epoch 20/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.2203 - accuracy: 0.9214 - val_loss: 1.8052 - val_accuracy: 0.6486\n",
            "Epoch 21/25\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 0.2055 - accuracy: 0.9258 - val_loss: 1.9486 - val_accuracy: 0.6432\n",
            "Epoch 22/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.1961 - accuracy: 0.9305 - val_loss: 1.9932 - val_accuracy: 0.6388\n",
            "Epoch 23/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.1724 - accuracy: 0.9385 - val_loss: 2.1479 - val_accuracy: 0.6468\n",
            "Epoch 24/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.1710 - accuracy: 0.9389 - val_loss: 2.1956 - val_accuracy: 0.6504\n",
            "Epoch 25/25\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 0.1574 - accuracy: 0.9429 - val_loss: 2.3327 - val_accuracy: 0.6466\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3403 - accuracy: 0.9279\n",
            "Test loss: 0.3402903378009796\n",
            "Test accuracy: 0.9279400110244751\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (1, 16, 16, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (1, 8, 8, 16)            0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation_36 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_37 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "225/225 [==============================] - 3s 9ms/step - loss: 1.6881 - accuracy: 0.3852 - val_loss: 1.3889 - val_accuracy: 0.4998\n",
            "Epoch 2/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 1.2823 - accuracy: 0.5395 - val_loss: 1.1837 - val_accuracy: 0.5786\n",
            "Epoch 3/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 1.1190 - accuracy: 0.6034 - val_loss: 1.0877 - val_accuracy: 0.6170\n",
            "Epoch 4/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 1.0174 - accuracy: 0.6402 - val_loss: 1.0346 - val_accuracy: 0.6374\n",
            "Epoch 5/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.9155 - accuracy: 0.6791 - val_loss: 0.9901 - val_accuracy: 0.6532\n",
            "Epoch 6/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.8484 - accuracy: 0.7018 - val_loss: 1.0126 - val_accuracy: 0.6524\n",
            "Epoch 7/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.7747 - accuracy: 0.7278 - val_loss: 0.9528 - val_accuracy: 0.6806\n",
            "Epoch 8/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.6945 - accuracy: 0.7548 - val_loss: 0.9766 - val_accuracy: 0.6694\n",
            "Epoch 9/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.6449 - accuracy: 0.7727 - val_loss: 0.9894 - val_accuracy: 0.6762\n",
            "Epoch 10/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.5739 - accuracy: 0.7963 - val_loss: 1.0221 - val_accuracy: 0.6726\n",
            "Epoch 11/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.5169 - accuracy: 0.8184 - val_loss: 1.0746 - val_accuracy: 0.6662\n",
            "Epoch 12/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.4475 - accuracy: 0.8422 - val_loss: 1.1580 - val_accuracy: 0.6666\n",
            "Epoch 13/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8568 - val_loss: 1.2574 - val_accuracy: 0.6600\n",
            "Epoch 14/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.3234 - accuracy: 0.8865 - val_loss: 1.3163 - val_accuracy: 0.6572\n",
            "Epoch 15/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.2827 - accuracy: 0.8985 - val_loss: 1.4865 - val_accuracy: 0.6496\n",
            "Epoch 16/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.2349 - accuracy: 0.9161 - val_loss: 1.5593 - val_accuracy: 0.6520\n",
            "Epoch 17/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.2198 - accuracy: 0.9219 - val_loss: 1.6665 - val_accuracy: 0.6488\n",
            "Epoch 18/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1831 - accuracy: 0.9346 - val_loss: 1.7601 - val_accuracy: 0.6558\n",
            "Epoch 19/25\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.1575 - accuracy: 0.9444 - val_loss: 1.8640 - val_accuracy: 0.6434\n",
            "Epoch 20/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1413 - accuracy: 0.9500 - val_loss: 2.0602 - val_accuracy: 0.6412\n",
            "Epoch 21/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1396 - accuracy: 0.9498 - val_loss: 2.0967 - val_accuracy: 0.6518\n",
            "Epoch 22/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1203 - accuracy: 0.9579 - val_loss: 2.1528 - val_accuracy: 0.6572\n",
            "Epoch 23/25\n",
            "225/225 [==============================] - 2s 9ms/step - loss: 0.1261 - accuracy: 0.9552 - val_loss: 2.3091 - val_accuracy: 0.6408\n",
            "Epoch 24/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1005 - accuracy: 0.9641 - val_loss: 2.4897 - val_accuracy: 0.6524\n",
            "Epoch 25/25\n",
            "225/225 [==============================] - 2s 8ms/step - loss: 0.1071 - accuracy: 0.9625 - val_loss: 2.5281 - val_accuracy: 0.6404\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3521 - accuracy: 0.9297\n",
            "Test loss: 0.3521101474761963\n",
            "Test accuracy: 0.9297000169754028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the accuracy of different batch size\n",
        "a = range(len(batchsize_list))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(a, Accuracy2, \"*\")\n",
        "#plt.scatter(a, Accuracy)\n",
        "\n",
        "ax.set_xticks(a)\n",
        "ax.set_xticklabels(batchsize_list)\n",
        "\n",
        "plt.xlabel('batch size')\n",
        "plt.xlabel('accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "SkztVv2zXsy5",
        "outputId": "34600dfb-2e6d-49d5-f604-b9eb269e16ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Accuracy2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrgBxAPZCvb",
        "outputId": "f8524ed4-708d-40cd-a759-c73913b25526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9039199948310852, 0.9319599866867065, 0.9172000288963318, 0.9109600186347961, 0.9246199727058411, 0.9423999786376953, 0.9279400110244751, 0.9297000169754028]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best performance model"
      ],
      "metadata": {
        "id": "v8gfUsSIYhvV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y8FYjd-e_xa",
        "outputId": "6e781ac9-354b-4278-886d-faa9ce604ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (1, 32, 32, 6)            456       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (1, 16, 16, 6)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (1, 16, 16, 16)           2416      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (1, 8, 8, 16)            0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (1, 8, 8, 120)            48120     \n",
            "                                                                 \n",
            " flatten (Flatten)           (1, 7680)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (1, 84)                   645204    \n",
            "                                                                 \n",
            " activation (Activation)     (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 697,046\n",
            "Trainable params: 697,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Build a LeNet Convolutional Neural Network\n",
        "\n",
        "cnn_model = keras.Sequential()\n",
        "#layer 1-2\n",
        "cnn_model.add(keras.layers.Conv2D(6, kernel_size=(5, 5),padding='same', activation=\"relu\"))\n",
        "cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#layer 3-4\n",
        "cnn_model.add(keras.layers.Conv2D(16, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "cnn_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "#layer 5\n",
        "cnn_model.add(keras.layers.Conv2D(120, kernel_size=(5, 5), padding='same',activation=\"relu\"))\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "cnn_model.add(keras.layers.Flatten())\n",
        "#layer 6\n",
        "cnn_model.add(keras.layers.Dense(84))\n",
        "cnn_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "# layer 7 output layer\n",
        "cnn_model.add(keras.layers.Dense(n_class))\n",
        "cnn_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "cnn_model.build(input_shape=(1,32,32,3))\n",
        "# print summary of the model\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORf457XM0t97",
        "outputId": "81a26939-61df-4a26-870c-acd8fed5c1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "352/352 [==============================] - 11s 7ms/step - loss: 1.6300 - accuracy: 0.4130 - val_loss: 1.3891 - val_accuracy: 0.5070\n",
            "Epoch 2/25\n",
            "352/352 [==============================] - 2s 5ms/step - loss: 1.2887 - accuracy: 0.5414 - val_loss: 1.2062 - val_accuracy: 0.5614\n",
            "Epoch 3/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.1260 - accuracy: 0.6015 - val_loss: 1.1009 - val_accuracy: 0.6152\n",
            "Epoch 4/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 1.0073 - accuracy: 0.6445 - val_loss: 1.0156 - val_accuracy: 0.6422\n",
            "Epoch 5/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.9048 - accuracy: 0.6799 - val_loss: 0.9538 - val_accuracy: 0.6706\n",
            "Epoch 6/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.8257 - accuracy: 0.7123 - val_loss: 0.9465 - val_accuracy: 0.6716\n",
            "Epoch 7/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.7452 - accuracy: 0.7406 - val_loss: 0.9309 - val_accuracy: 0.6854\n",
            "Epoch 8/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6756 - accuracy: 0.7626 - val_loss: 0.9378 - val_accuracy: 0.6896\n",
            "Epoch 9/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.6064 - accuracy: 0.7890 - val_loss: 0.9806 - val_accuracy: 0.6776\n",
            "Epoch 10/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.5312 - accuracy: 0.8154 - val_loss: 0.9471 - val_accuracy: 0.6996\n",
            "Epoch 11/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4633 - accuracy: 0.8389 - val_loss: 0.9798 - val_accuracy: 0.6962\n",
            "Epoch 12/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.4015 - accuracy: 0.8607 - val_loss: 1.0413 - val_accuracy: 0.6940\n",
            "Epoch 13/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.3327 - accuracy: 0.8847 - val_loss: 1.1686 - val_accuracy: 0.6854\n",
            "Epoch 14/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2816 - accuracy: 0.9023 - val_loss: 1.2710 - val_accuracy: 0.6680\n",
            "Epoch 15/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.9188 - val_loss: 1.3632 - val_accuracy: 0.6744\n",
            "Epoch 16/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1933 - accuracy: 0.9336 - val_loss: 1.4266 - val_accuracy: 0.6774\n",
            "Epoch 17/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1565 - accuracy: 0.9459 - val_loss: 1.5628 - val_accuracy: 0.6696\n",
            "Epoch 18/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1395 - accuracy: 0.9523 - val_loss: 1.6803 - val_accuracy: 0.6800\n",
            "Epoch 19/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1073 - accuracy: 0.9636 - val_loss: 1.7821 - val_accuracy: 0.6794\n",
            "Epoch 20/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 1.9236 - val_accuracy: 0.6692\n",
            "Epoch 21/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 1.9137 - val_accuracy: 0.6772\n",
            "Epoch 22/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0984 - accuracy: 0.9656 - val_loss: 2.0986 - val_accuracy: 0.6772\n",
            "Epoch 23/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0794 - accuracy: 0.9728 - val_loss: 2.1840 - val_accuracy: 0.6702\n",
            "Epoch 24/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0883 - accuracy: 0.9692 - val_loss: 2.2818 - val_accuracy: 0.6614\n",
            "Epoch 25/25\n",
            "352/352 [==============================] - 2s 6ms/step - loss: 0.0744 - accuracy: 0.9753 - val_loss: 2.2963 - val_accuracy: 0.6742\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2910 - accuracy: 0.9464\n",
            "Test loss: 0.29097694158554077\n",
            "Test accuracy: 0.9464399814605713\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "\n",
        "#define the optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# compile the model\n",
        "cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "cnn_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = cnn_model.evaluate(image_train, class_train)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equivalent feedforwad network"
      ],
      "metadata": {
        "id": "I1EQyh8SYnvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a equivalent feed forward network of the LeNet Convolutional Neural Network\n",
        "\n",
        "ff_model = keras.Sequential()\n",
        "\n",
        "#flatten 2d data to 1d\n",
        "ff_model.add(keras.layers.Flatten())\n",
        "\n",
        "#layer 1-2\n",
        "ff_model.add(keras.layers.Dense(6))\n",
        "#ff_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "#layer 3-4\n",
        "ff_model.add(keras.layers.Dense(16))\n",
        "#ff_model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "#layer 5\n",
        "ff_model.add(keras.layers.Dense(120))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "\n",
        "#layer 6\n",
        "ff_model.add(keras.layers.Dense(84))\n",
        "ff_model.add(keras.layers.Activation('relu'))\n",
        "\n",
        "# layer 7 output layer\n",
        "ff_model.add(keras.layers.Dense(n_class))\n",
        "ff_model.add(keras.layers.Activation('softmax'))\n",
        "\n",
        "ff_model.build(input_shape=(1,32,32,3))\n",
        "# print summary of the model\n",
        "ff_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6LOjZQuHHrl",
        "outputId": "c328cfaa-7f0c-4245-ffbb-3d17c8df183d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (1, 3072)                 0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (1, 6)                    18438     \n",
            "                                                                 \n",
            " activation_38 (Activation)  (1, 6)                    0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (1, 16)                   112       \n",
            "                                                                 \n",
            " activation_39 (Activation)  (1, 16)                   0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (1, 120)                  2040      \n",
            "                                                                 \n",
            " activation_40 (Activation)  (1, 120)                  0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (1, 84)                   10164     \n",
            "                                                                 \n",
            " activation_41 (Activation)  (1, 84)                   0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (1, 10)                   850       \n",
            "                                                                 \n",
            " activation_42 (Activation)  (1, 10)                   0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,604\n",
            "Trainable params: 31,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "epochs = 25\n",
        "batch_size = 128\n",
        "\n",
        "#define the optimizer\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "# compile the model\n",
        "ff_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "# train the model\n",
        "ff_model.fit(image_train, class_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "# Evaluate\n",
        "score = ff_model.evaluate(image_train, class_train)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhiNzXSSIDtH",
        "outputId": "e4f8f42b-7305-4bf6-9938-4a54d7ef21c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 2.0655 - accuracy: 0.2138 - val_loss: 2.0190 - val_accuracy: 0.2390\n",
            "Epoch 2/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9475 - accuracy: 0.2626 - val_loss: 1.9502 - val_accuracy: 0.2628\n",
            "Epoch 3/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9305 - accuracy: 0.2693 - val_loss: 1.9204 - val_accuracy: 0.2658\n",
            "Epoch 4/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9194 - accuracy: 0.2733 - val_loss: 1.9537 - val_accuracy: 0.2564\n",
            "Epoch 5/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.9140 - accuracy: 0.2731 - val_loss: 1.9199 - val_accuracy: 0.2702\n",
            "Epoch 6/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9107 - accuracy: 0.2769 - val_loss: 1.9159 - val_accuracy: 0.2750\n",
            "Epoch 7/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9052 - accuracy: 0.2749 - val_loss: 1.9108 - val_accuracy: 0.2812\n",
            "Epoch 8/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9031 - accuracy: 0.2783 - val_loss: 1.9128 - val_accuracy: 0.2708\n",
            "Epoch 9/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.9005 - accuracy: 0.2813 - val_loss: 1.9116 - val_accuracy: 0.2772\n",
            "Epoch 10/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8988 - accuracy: 0.2807 - val_loss: 1.9167 - val_accuracy: 0.2686\n",
            "Epoch 11/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8957 - accuracy: 0.2832 - val_loss: 1.9064 - val_accuracy: 0.2788\n",
            "Epoch 12/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8970 - accuracy: 0.2836 - val_loss: 1.9135 - val_accuracy: 0.2716\n",
            "Epoch 13/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8941 - accuracy: 0.2823 - val_loss: 1.9172 - val_accuracy: 0.2726\n",
            "Epoch 14/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8922 - accuracy: 0.2845 - val_loss: 1.9053 - val_accuracy: 0.2858\n",
            "Epoch 15/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8896 - accuracy: 0.2855 - val_loss: 1.9122 - val_accuracy: 0.2712\n",
            "Epoch 16/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8897 - accuracy: 0.2855 - val_loss: 1.9087 - val_accuracy: 0.2830\n",
            "Epoch 17/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8898 - accuracy: 0.2871 - val_loss: 1.9118 - val_accuracy: 0.2770\n",
            "Epoch 18/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8879 - accuracy: 0.2875 - val_loss: 1.9478 - val_accuracy: 0.2702\n",
            "Epoch 19/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8869 - accuracy: 0.2862 - val_loss: 1.9001 - val_accuracy: 0.2844\n",
            "Epoch 20/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8869 - accuracy: 0.2890 - val_loss: 1.9136 - val_accuracy: 0.2788\n",
            "Epoch 21/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8852 - accuracy: 0.2890 - val_loss: 1.9071 - val_accuracy: 0.2826\n",
            "Epoch 22/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8834 - accuracy: 0.2889 - val_loss: 1.9000 - val_accuracy: 0.2858\n",
            "Epoch 23/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8828 - accuracy: 0.2898 - val_loss: 1.9008 - val_accuracy: 0.2818\n",
            "Epoch 24/25\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 1.8832 - accuracy: 0.2928 - val_loss: 1.9043 - val_accuracy: 0.2876\n",
            "Epoch 25/25\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 1.8820 - accuracy: 0.2897 - val_loss: 1.9099 - val_accuracy: 0.2782\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8845 - accuracy: 0.2880\n",
            "Test loss: 1.8844664096832275\n",
            "Test accuracy: 0.2880200147628784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUpDBTWpfAEK"
      },
      "source": [
        "# Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z86zoajn3mZg"
      },
      "source": [
        "1. The dimensions of the input is (6, 6, 1), the kernel's size is (3, 3, 1).  There are 10 parameters in the kernel f.\n",
        "\n",
        "2. The output activation map when you apply the convolutional operation using the filter f on the input X without padding is: \n",
        "\n",
        "[[ 16.   9.  -4. -18.]\n",
        " [ 17.  -5. -10. -12.]\n",
        " [ 11.  -9. -17.   2.]\n",
        " [  9.  -1. -15.  16.]]\n",
        "\n",
        "3. the output when you apply a max-pooling operation on the output from the activation map with a pooling filter size of 2 and stride of 2 is:\n",
        "\n",
        "[[17. -4.]\n",
        " [11. 16.]]\n",
        "\n",
        "A pooling filter size of 2 and stride of 1 is:\n",
        "\n",
        "[[17.  9. -4.]\n",
        " [17. -5.  2.]\n",
        " [11. -1. 16.]]\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZFJmn6qwBX2y"
      },
      "outputs": [],
      "source": [
        "# function to convlutional\n",
        "# s is stride\n",
        "def conv(input, filter, s = 1):\n",
        "\n",
        "  H = input.shape[0]\n",
        "  F = filter.shape[0]\n",
        "\n",
        "  out_h = H-F+1\n",
        "  acti_map = np.zeros((out_h,out_h))\n",
        "\n",
        "  for j in range(out_h):\n",
        "\n",
        "    for i in range(out_h):\n",
        "\n",
        "      sub_input = input[j:j+F,i:i+F]\n",
        "\n",
        "      acti_map[j, i] = np.sum(sub_input*filter)\n",
        "\n",
        "  return acti_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yMsnASbH5VP2"
      },
      "outputs": [],
      "source": [
        "# function to pool\n",
        "# s is stride, f is filter\n",
        "def max_pooling(arr, f = 2, s = 2):\n",
        "\n",
        "  h = arr.shape[0]\n",
        "\n",
        "  out_h = (h-f)//s+1\n",
        "  output = np.zeros((out_h,out_h))\n",
        "\n",
        "  for j in range(out_h):\n",
        "    starty = j*s\n",
        "    for i in range(out_h):\n",
        "\n",
        "      startx = i*s\n",
        "\n",
        "      sub_input = arr[starty:starty+f,startx:startx+f]\n",
        "      #print(sub_input)\n",
        "\n",
        "      output[j, i] = np.max(sub_input)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inout\n",
        "arr_1d = np.array([7,5,0,0,3,2,\n",
        "              6,4,5,1,4,8,\n",
        "              9,0,2,2,5,4,\n",
        "              6,3,4,7,9,8,\n",
        "              5,7,5,6,9,0,\n",
        "              7,9,0,8,2,3])\n",
        "filt = np.array([1,0,-1,\n",
        "             2, 0, -2,\n",
        "             1, 0, -1])\n",
        "\n",
        "arr_2d = arr_1d.reshape(6,6)\n",
        "filt = filt.reshape(3, 3)\n",
        "\n",
        "# call function to conv\n",
        "activation_map = conv(arr_2d, filt)\n",
        "# call function to pool\n",
        "pool_map = max_pooling(activation_map, f = 2, s = 2)\n"
      ],
      "metadata": {
        "id": "5lC2hXX9DkcV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(activation_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M63_wjD0D4CB",
        "outputId": "7df0106d-4858-41a1-8256-c38b7b5be516"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 16.   9.  -4. -18.]\n",
            " [ 17.  -5. -10. -12.]\n",
            " [ 11.  -9. -17.   2.]\n",
            " [  9.  -1. -15.  16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pool_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XheigLe2D60C",
        "outputId": "82c38740-e43f-45b0-8302-1706cad7c1a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17. -4.]\n",
            " [11. 16.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(max_pooling(activation_map, f = 2, s = 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7WuuyUjG9wX",
        "outputId": "e6846d9c-5d83-4fa9-99ba-a30ef84b3d4e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17.  9. -4.]\n",
            " [17. -5.  2.]\n",
            " [11. -1. 16.]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}